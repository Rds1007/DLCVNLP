{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r\"C:\\Users\\Ramdhan\\Desktop\\DLCVNLP\\TensorFlow\\Home Work\\Salary_Forcast\\adult.data\",sep=',',\n",
    "                 names=['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('salary',axis=\"columns\")\n",
    "X_cat = X.select_dtypes(include=[object])\n",
    "X_noncatc = X.select_dtypes(exclude=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying One Hot Encoding \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "df_processed_np = ohe.fit_transform(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([X_noncatc,pd.DataFrame(df_processed_np)],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "salary            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Null Values Check \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "fnlwgt             int64\n",
       "education         object\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "salary            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' United-States', ' Cuba', ' Jamaica', ' India', ' ?', ' Mexico',\n",
       "       ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada',\n",
       "       ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland',\n",
       "       ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos',\n",
       "       ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic',\n",
       "       ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan',\n",
       "       ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland',\n",
       "       ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong',\n",
       "       ' Ireland', ' Hungary', ' Holand-Netherlands'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['native-country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load data\n",
    "data = x\n",
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit and transform in one step\n",
    "normalized = scaler.fit_transform(data)\n",
    "# inverse transform\n",
    "#inverse = scaler.inverse_transform(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = np.where(df['salary']==' <=50K',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Label Encoding\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le=LabelEncoder()\n",
    "#X.loc[:,['workclass','education','marital-status','occupation','relationship','race','sex','native-country']]=\\\n",
    "#X.loc[:,['workclass','education','marital-status','occupation','relationship','race','sex','native-country']].apply(le.fit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns =[]\n",
    "for i in X.columns:\n",
    "    if (type(X[i][0]) is str):\n",
    "        cat_columns.append(i)\n",
    "        rest_df =df.drop\n",
    "cat_columns_idx = [X.columns.get_loc(col) for col in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 6, 7, 8, 9, 13]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.get_dummies(data=X, columns=['workclass','education','marital-status','occupation','relationship','race','sex','native-country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048238</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.138113</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.151068</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.221488</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.094827</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.128499</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.187203</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3    4         5    6    7    8    \\\n",
       "0      0.301370  0.044302  0.800000  0.021740  0.0  0.397959  0.0  0.0  0.0   \n",
       "1      0.452055  0.048238  0.800000  0.000000  0.0  0.122449  0.0  0.0  0.0   \n",
       "2      0.287671  0.138113  0.533333  0.000000  0.0  0.397959  0.0  0.0  0.0   \n",
       "3      0.493151  0.151068  0.400000  0.000000  0.0  0.397959  0.0  0.0  0.0   \n",
       "4      0.150685  0.221488  0.800000  0.000000  0.0  0.397959  0.0  0.0  0.0   \n",
       "...         ...       ...       ...       ...  ...       ...  ...  ...  ...   \n",
       "32556  0.136986  0.166404  0.733333  0.000000  0.0  0.377551  0.0  0.0  0.0   \n",
       "32557  0.315068  0.096500  0.533333  0.000000  0.0  0.397959  0.0  0.0  0.0   \n",
       "32558  0.561644  0.094827  0.533333  0.000000  0.0  0.397959  0.0  0.0  0.0   \n",
       "32559  0.068493  0.128499  0.533333  0.000000  0.0  0.193878  0.0  0.0  0.0   \n",
       "32560  0.479452  0.187203  0.533333  0.150242  0.0  0.397959  0.0  0.0  0.0   \n",
       "\n",
       "       9    ...  98   99   100  101  102  103  104  105  106  107  \n",
       "0      0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1      0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2      0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3      0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4      0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "32556  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "32557  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "32558  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "32559  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "32560  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[32561 rows x 108 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= pd.DataFrame(normalized)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NN for Salary Prediction Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize all the data points and cast the labels to int64\n",
    "import tensorflow as tf\n",
    "train_x, test_x = tf.cast(train_x, tf.int64), tf.cast(test_x, tf.int64)\n",
    "train_y, test_y = tf.cast(train_y,tf.int64),tf.cast(test_y,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "salmodel = tf.keras.models.Sequential();\n",
    "salmodel.add(tf.keras.layers.Flatten())\n",
    "salmodel.add(tf.keras.layers.Dense(108,input_dim=108, activation='relu'))\n",
    "salmodel.add(tf.keras.layers.Dense(54, activation='relu'))\n",
    "salmodel.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "salmodel.compile (optimizer= tf.keras.optimizers.Adam(), loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3676 - accuracy: 0.8284\n",
      "Epoch 2/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3558 - accuracy: 0.8340\n",
      "Epoch 3/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3525 - accuracy: 0.8357\n",
      "Epoch 4/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3485 - accuracy: 0.8366\n",
      "Epoch 5/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3461 - accuracy: 0.8381\n",
      "Epoch 6/50\n",
      "3663/3663 [==============================] - 9s 2ms/step - loss: 0.3429 - accuracy: 0.8400\n",
      "Epoch 7/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3407 - accuracy: 0.8404\n",
      "Epoch 8/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3377 - accuracy: 0.8424\n",
      "Epoch 9/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3349 - accuracy: 0.8428\n",
      "Epoch 10/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.3312 - accuracy: 0.8445\n",
      "Epoch 11/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3289 - accuracy: 0.8459\n",
      "Epoch 12/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3264 - accuracy: 0.8469\n",
      "Epoch 13/50\n",
      "3663/3663 [==============================] - 9s 2ms/step - loss: 0.3231 - accuracy: 0.8479\n",
      "Epoch 14/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3200 - accuracy: 0.8488\n",
      "Epoch 15/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3178 - accuracy: 0.8501\n",
      "Epoch 16/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3156 - accuracy: 0.8509\n",
      "Epoch 17/50\n",
      "3663/3663 [==============================] - 9s 2ms/step - loss: 0.3128 - accuracy: 0.8517\n",
      "Epoch 18/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3108 - accuracy: 0.8525\n",
      "Epoch 19/50\n",
      "3663/3663 [==============================] - 7s 2ms/step - loss: 0.3089 - accuracy: 0.8534\n",
      "Epoch 20/50\n",
      "3663/3663 [==============================] - 7s 2ms/step - loss: 0.3070 - accuracy: 0.8547\n",
      "Epoch 21/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.3052 - accuracy: 0.8541\n",
      "Epoch 22/50\n",
      "3663/3663 [==============================] - 7s 2ms/step - loss: 0.3037 - accuracy: 0.8556\n",
      "Epoch 23/50\n",
      "3663/3663 [==============================] - 7s 2ms/step - loss: 0.3028 - accuracy: 0.8556\n",
      "Epoch 24/50\n",
      "3663/3663 [==============================] - 7s 2ms/step - loss: 0.3005 - accuracy: 0.8564\n",
      "Epoch 25/50\n",
      "3663/3663 [==============================] - 9s 3ms/step - loss: 0.3008 - accuracy: 0.8558\n",
      "Epoch 26/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2985 - accuracy: 0.8567\n",
      "Epoch 27/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2980 - accuracy: 0.8580\n",
      "Epoch 28/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2968 - accuracy: 0.8583\n",
      "Epoch 29/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2957 - accuracy: 0.8593\n",
      "Epoch 30/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2951 - accuracy: 0.8587\n",
      "Epoch 31/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2946 - accuracy: 0.8587\n",
      "Epoch 32/50\n",
      "3663/3663 [==============================] - 9s 2ms/step - loss: 0.2934 - accuracy: 0.8586\n",
      "Epoch 33/50\n",
      "3663/3663 [==============================] - 9s 3ms/step - loss: 0.2930 - accuracy: 0.8592\n",
      "Epoch 34/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2925 - accuracy: 0.8591\n",
      "Epoch 35/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2917 - accuracy: 0.8598\n",
      "Epoch 36/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2908 - accuracy: 0.8593\n",
      "Epoch 37/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2904 - accuracy: 0.8596\n",
      "Epoch 38/50\n",
      "3663/3663 [==============================] - 11s 3ms/step - loss: 0.2903 - accuracy: 0.8602\n",
      "Epoch 39/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2892 - accuracy: 0.8609\n",
      "Epoch 40/50\n",
      "3663/3663 [==============================] - 9s 2ms/step - loss: 0.2898 - accuracy: 0.8609\n",
      "Epoch 41/50\n",
      "3663/3663 [==============================] - 10s 3ms/step - loss: 0.2887 - accuracy: 0.8603\n",
      "Epoch 42/50\n",
      "3663/3663 [==============================] - 7s 2ms/step - loss: 0.2884 - accuracy: 0.8605\n",
      "Epoch 43/50\n",
      "3663/3663 [==============================] - 9s 2ms/step - loss: 0.2879 - accuracy: 0.8610\n",
      "Epoch 44/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2872 - accuracy: 0.8615\n",
      "Epoch 45/50\n",
      "3663/3663 [==============================] - 9s 2ms/step - loss: 0.2875 - accuracy: 0.8608\n",
      "Epoch 46/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2865 - accuracy: 0.8617\n",
      "Epoch 47/50\n",
      "3663/3663 [==============================] - 7s 2ms/step - loss: 0.2875 - accuracy: 0.8621\n",
      "Epoch 48/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2853 - accuracy: 0.8618\n",
      "Epoch 49/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2863 - accuracy: 0.8624\n",
      "Epoch 50/50\n",
      "3663/3663 [==============================] - 8s 2ms/step - loss: 0.2856 - accuracy: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x275b41fd5f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salmodel.fit(train_x, train_y, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.8207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7517264485359192, 0.8206939101219177]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salmodel.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = salmodel.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =[]\n",
    "for i in range(len(predict)):\n",
    "    y_pred.append(np.where(predict[i]>0.5,1,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(y_pred,columns=['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      2444\n",
      "           1       0.70      0.49      0.58       813\n",
      "\n",
      "    accuracy                           0.82      3257\n",
      "   macro avg       0.77      0.71      0.73      3257\n",
      "weighted avg       0.81      0.82      0.81      3257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y,results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2274  170]\n",
      " [ 414  399]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(test_y, results)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "salmodel.save(\"salmodel2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
