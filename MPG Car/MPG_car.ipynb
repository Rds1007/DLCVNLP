{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Dataset has been taken from UCI data repository.\n",
    "this predicts the Miles Per gallon based in the certain attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Ramdhan\\Desktop\\DLCVNLP\\TensorFlow\\Home Work\\MPG_Reg\\auto-mpg.data\",header=None,delim_whitespace=True,\n",
    "                 names=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0      130.0  3504.0          12.0   \n",
       "1    15.0          8         350.0      165.0  3693.0          11.5   \n",
       "2    18.0          8         318.0      150.0  3436.0          11.0   \n",
       "3    16.0          8         304.0      150.0  3433.0          12.0   \n",
       "4    17.0          8         302.0      140.0  3449.0          10.5   \n",
       "..    ...        ...           ...        ...     ...           ...   \n",
       "393  27.0          4         140.0      86.00  2790.0          15.6   \n",
       "394  44.0          4          97.0      52.00  2130.0          24.6   \n",
       "395  32.0          4         135.0      84.00  2295.0          11.6   \n",
       "396  28.0          4         120.0      79.00  2625.0          18.6   \n",
       "397  31.0          4         119.0      82.00  2720.0          19.4   \n",
       "\n",
       "     model year  origin                   car name  \n",
       "0            70       1  chevrolet chevelle malibu  \n",
       "1            70       1          buick skylark 320  \n",
       "2            70       1         plymouth satellite  \n",
       "3            70       1              amc rebel sst  \n",
       "4            70       1                ford torino  \n",
       "..          ...     ...                        ...  \n",
       "393          82       1            ford mustang gl  \n",
       "394          82       2                  vw pickup  \n",
       "395          82       1              dodge rampage  \n",
       "396          82       1                ford ranger  \n",
       "397          82       1                 chevy s-10  \n",
       "\n",
       "[398 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower       object\n",
       "weight          float64\n",
       "acceleration    float64\n",
       "model year        int64\n",
       "origin            int64\n",
       "car name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    float64\n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car name      398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = 82-df['model year']\n",
    "\n",
    "df['horsepower'] = pd.to_numeric(df.horsepower, errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels =['model year','car name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.astype('int64',copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.iloc[:,1:9] #removed target and car names\n",
    "y=df['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(X))\n",
    "x=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.617571</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.536150</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.589736</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645995</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.516870</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.516019</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.520556</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.373913</td>\n",
       "      <td>0.333711</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.074935</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.146583</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.173127</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.193365</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.134367</td>\n",
       "      <td>0.343478</td>\n",
       "      <td>0.286929</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.356522</td>\n",
       "      <td>0.313864</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4    5    6\n",
       "0    1.0  0.617571  0.565217  0.536150  0.238095  0.0  1.0\n",
       "1    1.0  0.728682  0.717391  0.589736  0.208333  0.0  1.0\n",
       "2    1.0  0.645995  0.652174  0.516870  0.178571  0.0  1.0\n",
       "3    1.0  0.609819  0.652174  0.516019  0.238095  0.0  1.0\n",
       "4    1.0  0.604651  0.608696  0.520556  0.148810  0.0  1.0\n",
       "..   ...       ...       ...       ...       ...  ...  ...\n",
       "393  0.2  0.186047  0.373913  0.333711  0.452381  0.0  0.0\n",
       "394  0.2  0.074935  0.226087  0.146583  0.988095  0.5  0.0\n",
       "395  0.2  0.173127  0.365217  0.193365  0.214286  0.0  0.0\n",
       "396  0.2  0.134367  0.343478  0.286929  0.630952  0.0  0.0\n",
       "397  0.2  0.131783  0.356522  0.313864  0.678571  0.0  0.0\n",
       "\n",
       "[398 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NN for MPG regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize all the data points and cast the labels to int64\n",
    "import tensorflow as tf\n",
    "train_x, test_x = tf.cast(train_x, tf.float32), tf.cast(test_x, tf.float32)\n",
    "train_y, test_y = tf.cast(train_y,tf.float32),tf.cast(test_y,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpgmodel = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(7,input_dim=7,activation=tf.nn.relu),  \n",
    "tf.keras.layers.Dense(343,activation=tf.nn.relu),\n",
    "tf.keras.layers.Dense(49,activation=tf.nn.relu), \n",
    "tf.keras.layers.Dense(1,activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.Adam()\n",
    "mpgmodel.compile(optimizer= optimiser, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 593.4869 - val_loss: 533.6908\n",
      "Epoch 2/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 381.1061 - val_loss: 165.3325\n",
      "Epoch 3/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 110.6395 - val_loss: 78.2701\n",
      "Epoch 4/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 69.2509 - val_loss: 63.9971\n",
      "Epoch 5/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 56.1656 - val_loss: 53.6479\n",
      "Epoch 6/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 47.3994 - val_loss: 46.6473\n",
      "Epoch 7/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 39.9122 - val_loss: 42.3558\n",
      "Epoch 8/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 34.4621 - val_loss: 35.1872\n",
      "Epoch 9/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 29.6933 - val_loss: 30.4604\n",
      "Epoch 10/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 24.5862 - val_loss: 27.9696\n",
      "Epoch 11/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 22.4709 - val_loss: 24.5735\n",
      "Epoch 12/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 18.58 - 0s 7ms/step - loss: 19.7289 - val_loss: 23.5524\n",
      "Epoch 13/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 18.5402 - val_loss: 22.3787\n",
      "Epoch 14/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 18.5140 - val_loss: 24.9718\n",
      "Epoch 15/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 17.5942 - val_loss: 22.8115\n",
      "Epoch 16/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 16.7992 - val_loss: 20.6602\n",
      "Epoch 17/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 16.3979 - val_loss: 19.4903\n",
      "Epoch 18/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 15.7328 - val_loss: 18.9179\n",
      "Epoch 19/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 15.6985 - val_loss: 18.9559\n",
      "Epoch 20/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 14.7961 - val_loss: 18.8829\n",
      "Epoch 21/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 14.6179 - val_loss: 20.7209\n",
      "Epoch 22/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 15.3854 - val_loss: 18.4523\n",
      "Epoch 23/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 14.2347 - val_loss: 17.7705\n",
      "Epoch 24/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 13.9711 - val_loss: 17.0699\n",
      "Epoch 25/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 13.4198 - val_loss: 17.6387\n",
      "Epoch 26/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 14.0766 - val_loss: 16.3216\n",
      "Epoch 27/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 13.2918 - val_loss: 16.0982\n",
      "Epoch 28/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 13.6680 - val_loss: 15.6571\n",
      "Epoch 29/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.9486 - val_loss: 15.5358\n",
      "Epoch 30/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.8469 - val_loss: 15.4735\n",
      "Epoch 31/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.6583 - val_loss: 15.0340\n",
      "Epoch 32/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.4263 - val_loss: 16.0891\n",
      "Epoch 33/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.6847 - val_loss: 14.2965\n",
      "Epoch 34/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.3635 - val_loss: 14.1584\n",
      "Epoch 35/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.2981 - val_loss: 14.4043\n",
      "Epoch 36/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.9823 - val_loss: 13.6221\n",
      "Epoch 37/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 12.7015 - val_loss: 15.2192\n",
      "Epoch 38/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.8973 - val_loss: 13.1926\n",
      "Epoch 39/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.7628 - val_loss: 13.2220\n",
      "Epoch 40/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.6381 - val_loss: 12.9624\n",
      "Epoch 41/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.5264 - val_loss: 12.7063\n",
      "Epoch 42/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.3819 - val_loss: 12.6312\n",
      "Epoch 43/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.4235 - val_loss: 12.3835\n",
      "Epoch 44/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.3128 - val_loss: 12.2423\n",
      "Epoch 45/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.9487 - val_loss: 12.0493\n",
      "Epoch 46/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10.8848 - val_loss: 12.0685\n",
      "Epoch 47/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.0963 - val_loss: 11.7658\n",
      "Epoch 48/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.8101 - val_loss: 13.0893\n",
      "Epoch 49/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10.5487 - val_loss: 11.6640\n",
      "Epoch 50/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.7278 - val_loss: 11.8175\n",
      "Epoch 51/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.7666 - val_loss: 11.1406\n",
      "Epoch 52/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.7278 - val_loss: 11.9967\n",
      "Epoch 53/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.9750 - val_loss: 11.4388\n",
      "Epoch 54/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.1334 - val_loss: 10.9651\n",
      "Epoch 55/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.3871 - val_loss: 11.4473\n",
      "Epoch 56/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.1301 - val_loss: 10.4611\n",
      "Epoch 57/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.9395 - val_loss: 12.6139\n",
      "Epoch 58/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.1323 - val_loss: 10.4136\n",
      "Epoch 59/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.0394 - val_loss: 10.3846\n",
      "Epoch 60/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.7497 - val_loss: 10.4619\n",
      "Epoch 61/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.8567 - val_loss: 10.1673\n",
      "Epoch 62/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.6012 - val_loss: 10.0287\n",
      "Epoch 63/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.4329 - val_loss: 10.1100\n",
      "Epoch 64/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.6757 - val_loss: 10.1313\n",
      "Epoch 65/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.7447 - val_loss: 10.2969\n",
      "Epoch 66/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.9770 - val_loss: 10.7233\n",
      "Epoch 67/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 10.3104 - val_loss: 9.7133\n",
      "Epoch 68/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.3331 - val_loss: 9.5693\n",
      "Epoch 69/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2531 - val_loss: 9.5535\n",
      "Epoch 70/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2195 - val_loss: 10.3862\n",
      "Epoch 71/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.9379 - val_loss: 9.5796\n",
      "Epoch 72/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2348 - val_loss: 9.1334\n",
      "Epoch 73/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0524 - val_loss: 9.5135\n",
      "Epoch 74/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.4132 - val_loss: 9.7562\n",
      "Epoch 75/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.4198 - val_loss: 10.3303\n",
      "Epoch 76/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.1163 - val_loss: 9.4435\n",
      "Epoch 77/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.1643 - val_loss: 9.4024\n",
      "Epoch 78/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0531 - val_loss: 8.7521\n",
      "Epoch 79/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.9120 - val_loss: 8.7814\n",
      "Epoch 80/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7728 - val_loss: 8.7459\n",
      "Epoch 81/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7120 - val_loss: 8.6101\n",
      "Epoch 82/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.6669 - val_loss: 9.0700\n",
      "Epoch 83/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.5145 - val_loss: 9.0338\n",
      "Epoch 84/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.8753 - val_loss: 8.8707\n",
      "Epoch 85/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0983 - val_loss: 8.5213\n",
      "Epoch 86/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.9225 - val_loss: 8.7540\n",
      "Epoch 87/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.8155 - val_loss: 8.5781\n",
      "Epoch 88/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4323 - val_loss: 8.7698\n",
      "Epoch 89/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.8706 - val_loss: 8.4980\n",
      "Epoch 90/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.8537 - val_loss: 8.6015\n",
      "Epoch 91/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.1516 - val_loss: 10.8231\n",
      "Epoch 92/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6442 - val_loss: 8.5523\n",
      "Epoch 93/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6026 - val_loss: 9.1845\n",
      "Epoch 94/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0950 - val_loss: 8.1806\n",
      "Epoch 95/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4409 - val_loss: 8.3334\n",
      "Epoch 96/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6980 - val_loss: 8.9635\n",
      "Epoch 97/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.5667 - val_loss: 9.0222\n",
      "Epoch 98/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4007 - val_loss: 8.5935\n",
      "Epoch 99/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.3253 - val_loss: 9.1817\n",
      "Epoch 100/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.9419 - val_loss: 8.0917\n",
      "Epoch 101/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9615 - val_loss: 9.9247\n",
      "Epoch 102/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.4606 - val_loss: 8.8628\n",
      "Epoch 103/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.8367 - val_loss: 8.1124\n",
      "Epoch 104/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.5768 - val_loss: 8.0609\n",
      "Epoch 105/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4464 - val_loss: 8.2148\n",
      "Epoch 106/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2579 - val_loss: 8.1824\n",
      "Epoch 107/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.3162 - val_loss: 8.0990\n",
      "Epoch 108/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1213 - val_loss: 8.0548\n",
      "Epoch 109/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1973 - val_loss: 8.1468\n",
      "Epoch 110/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1625 - val_loss: 9.0488\n",
      "Epoch 111/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1563 - val_loss: 9.1219\n",
      "Epoch 112/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6823 - val_loss: 7.8479\n",
      "Epoch 113/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.8261 - val_loss: 8.1695\n",
      "Epoch 114/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8695 - val_loss: 8.9927\n",
      "Epoch 115/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.3427 - val_loss: 7.9227\n",
      "Epoch 116/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9181 - val_loss: 8.0037\n",
      "Epoch 117/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2273 - val_loss: 7.8569\n",
      "Epoch 118/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2624 - val_loss: 7.9631\n",
      "Epoch 119/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.8913 - val_loss: 8.0924\n",
      "Epoch 120/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9330 - val_loss: 7.7264\n",
      "Epoch 121/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9608 - val_loss: 10.2944\n",
      "Epoch 122/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.0076 - val_loss: 8.1823\n",
      "Epoch 123/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.5184 - val_loss: 7.6982\n",
      "Epoch 124/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2529 - val_loss: 10.3892\n",
      "Epoch 125/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.8048 - val_loss: 7.6800\n",
      "Epoch 126/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2933 - val_loss: 7.6436\n",
      "Epoch 127/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2163 - val_loss: 7.6982\n",
      "Epoch 128/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7090 - val_loss: 7.8917\n",
      "Epoch 129/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4483 - val_loss: 7.8111\n",
      "Epoch 130/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8639 - val_loss: 7.5886\n",
      "Epoch 131/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9518 - val_loss: 8.4633\n",
      "Epoch 132/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1412 - val_loss: 7.5270\n",
      "Epoch 133/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9346 - val_loss: 7.6888\n",
      "Epoch 134/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.3023 - val_loss: 7.3405\n",
      "Epoch 135/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8238 - val_loss: 7.6081\n",
      "Epoch 136/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8836 - val_loss: 7.5526\n",
      "Epoch 137/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9746 - val_loss: 7.6952\n",
      "Epoch 138/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8738 - val_loss: 7.4998\n",
      "Epoch 139/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9917 - val_loss: 7.4970\n",
      "Epoch 140/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8890 - val_loss: 7.6607\n",
      "Epoch 141/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6226 - val_loss: 8.7266\n",
      "Epoch 142/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9987 - val_loss: 7.5831\n",
      "Epoch 143/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4643 - val_loss: 8.0068\n",
      "Epoch 144/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6989 - val_loss: 7.5172\n",
      "Epoch 145/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7384 - val_loss: 8.5225\n",
      "Epoch 146/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.0369 - val_loss: 7.4568\n",
      "Epoch 147/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7098 - val_loss: 7.5539\n",
      "Epoch 148/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6288 - val_loss: 7.5756\n",
      "Epoch 149/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7580 - val_loss: 7.6399\n",
      "Epoch 150/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1497 - val_loss: 7.3858\n",
      "Epoch 151/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8272 - val_loss: 7.8401\n",
      "Epoch 152/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7585 - val_loss: 8.0580\n",
      "Epoch 153/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8754 - val_loss: 7.4853\n",
      "Epoch 154/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4995 - val_loss: 8.3512\n",
      "Epoch 155/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5979 - val_loss: 8.1039\n",
      "Epoch 156/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6163 - val_loss: 7.9033\n",
      "Epoch 157/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2860 - val_loss: 7.6009\n",
      "Epoch 158/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8482 - val_loss: 7.8303\n",
      "Epoch 159/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.0217 - val_loss: 7.8882\n",
      "Epoch 160/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7642 - val_loss: 8.0981\n",
      "Epoch 161/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6204 - val_loss: 7.9215\n",
      "Epoch 162/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9481 - val_loss: 7.6210\n",
      "Epoch 163/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9813 - val_loss: 8.0108\n",
      "Epoch 164/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5639 - val_loss: 7.7384\n",
      "Epoch 165/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6006 - val_loss: 7.5260\n",
      "Epoch 166/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5365 - val_loss: 7.3130\n",
      "Epoch 167/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6321 - val_loss: 7.6655\n",
      "Epoch 168/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4804 - val_loss: 9.5345\n",
      "Epoch 169/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0225 - val_loss: 7.7497\n",
      "Epoch 170/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8752 - val_loss: 7.6332\n",
      "Epoch 171/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6713 - val_loss: 8.4565\n",
      "Epoch 172/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7335 - val_loss: 8.8305\n",
      "Epoch 173/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.0394 - val_loss: 7.6147\n",
      "Epoch 174/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4348 - val_loss: 7.4735\n",
      "Epoch 175/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9526 - val_loss: 8.3581\n",
      "Epoch 176/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8102 - val_loss: 7.5051\n",
      "Epoch 177/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4759 - val_loss: 7.3968\n",
      "Epoch 178/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5389 - val_loss: 7.7941\n",
      "Epoch 179/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4644 - val_loss: 7.5246\n",
      "Epoch 180/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4305 - val_loss: 7.5889\n",
      "Epoch 181/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3186 - val_loss: 7.5988\n",
      "Epoch 182/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2611 - val_loss: 7.5883\n",
      "Epoch 183/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2979 - val_loss: 7.6339\n",
      "Epoch 184/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2061 - val_loss: 7.5016\n",
      "Epoch 185/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2420 - val_loss: 7.4834\n",
      "Epoch 186/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6905 - val_loss: 7.9931\n",
      "Epoch 187/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.1482 - val_loss: 8.3485\n",
      "Epoch 188/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1286 - val_loss: 8.1336\n",
      "Epoch 189/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6807 - val_loss: 7.4894\n",
      "Epoch 190/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.9865 - val_loss: 7.8531\n",
      "Epoch 191/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2357 - val_loss: 7.4146\n",
      "Epoch 192/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6829 - val_loss: 7.6969\n",
      "Epoch 193/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3412 - val_loss: 7.5726\n",
      "Epoch 194/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3096 - val_loss: 7.7138\n",
      "Epoch 195/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2672 - val_loss: 7.3809\n",
      "Epoch 196/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2101 - val_loss: 7.7737\n",
      "Epoch 197/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2753 - val_loss: 7.6269\n",
      "Epoch 198/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3986 - val_loss: 7.8528\n",
      "Epoch 199/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6037 - val_loss: 7.4346\n",
      "Epoch 200/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1806 - val_loss: 7.9529\n",
      "Epoch 201/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3202 - val_loss: 7.7886\n",
      "Epoch 202/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2871 - val_loss: 7.4515\n",
      "Epoch 203/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1696 - val_loss: 8.4983\n",
      "Epoch 204/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5774 - val_loss: 8.3579\n",
      "Epoch 205/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3723 - val_loss: 8.4074\n",
      "Epoch 206/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5488 - val_loss: 8.1304\n",
      "Epoch 207/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0536 - val_loss: 7.4434\n",
      "Epoch 208/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8522 - val_loss: 7.8982\n",
      "Epoch 209/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0953 - val_loss: 7.4384\n",
      "Epoch 210/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4691 - val_loss: 7.5509\n",
      "Epoch 211/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0760 - val_loss: 7.7667\n",
      "Epoch 212/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1615 - val_loss: 7.7344\n",
      "Epoch 213/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6903 - val_loss: 7.5793\n",
      "Epoch 214/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4261 - val_loss: 8.3970\n",
      "Epoch 215/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4385 - val_loss: 8.0246\n",
      "Epoch 216/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3597 - val_loss: 7.8085\n",
      "Epoch 217/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8701 - val_loss: 8.2422\n",
      "Epoch 218/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3977 - val_loss: 7.6644\n",
      "Epoch 219/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4749 - val_loss: 8.2317\n",
      "Epoch 220/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3638 - val_loss: 7.6691\n",
      "Epoch 221/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0745 - val_loss: 7.6078\n",
      "Epoch 222/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1271 - val_loss: 7.5551\n",
      "Epoch 223/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4384 - val_loss: 7.2079\n",
      "Epoch 224/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2975 - val_loss: 8.4189\n",
      "Epoch 225/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4548 - val_loss: 8.3595\n",
      "Epoch 226/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2080 - val_loss: 7.8825\n",
      "Epoch 227/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6188 - val_loss: 8.6243\n",
      "Epoch 228/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7207 - val_loss: 7.6747\n",
      "Epoch 229/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1784 - val_loss: 7.4831\n",
      "Epoch 230/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4881 - val_loss: 7.3659\n",
      "Epoch 231/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3475 - val_loss: 9.9117\n",
      "Epoch 232/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2673 - val_loss: 7.7603\n",
      "Epoch 233/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1580 - val_loss: 8.2466\n",
      "Epoch 234/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3583 - val_loss: 8.1495\n",
      "Epoch 235/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2224 - val_loss: 7.5383\n",
      "Epoch 236/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2657 - val_loss: 7.7367\n",
      "Epoch 237/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0175 - val_loss: 7.9479\n",
      "Epoch 238/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4224 - val_loss: 7.6463\n",
      "Epoch 239/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.5243 - val_loss: 8.1840\n",
      "Epoch 240/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 7.2107 - val_loss: 7.5605\n",
      "Epoch 241/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2738 - val_loss: 7.7200\n",
      "Epoch 242/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1956 - val_loss: 7.4548\n",
      "Epoch 243/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9626 - val_loss: 7.3998\n",
      "Epoch 244/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7485 - val_loss: 7.9752\n",
      "Epoch 245/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0904 - val_loss: 7.8551\n",
      "Epoch 246/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9171 - val_loss: 8.1306\n",
      "Epoch 247/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0195 - val_loss: 9.0661\n",
      "Epoch 248/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2651 - val_loss: 8.1189\n",
      "Epoch 249/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0548 - val_loss: 7.6419\n",
      "Epoch 250/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0507 - val_loss: 7.8215\n",
      "Epoch 251/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0154 - val_loss: 7.5957\n",
      "Epoch 252/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0457 - val_loss: 7.7711\n",
      "Epoch 253/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6161 - val_loss: 7.7661\n",
      "Epoch 254/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2626 - val_loss: 7.8342\n",
      "Epoch 255/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.0056 - val_loss: 7.5215\n",
      "Epoch 256/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 9.2019 - 0s 5ms/step - loss: 7.1190 - val_loss: 7.5669\n",
      "Epoch 257/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.2232 - val_loss: 7.6560\n",
      "Epoch 258/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0585 - val_loss: 7.5495\n",
      "Epoch 259/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0650 - val_loss: 7.7991\n",
      "Epoch 260/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1758 - val_loss: 8.3243\n",
      "Epoch 261/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2184 - val_loss: 7.5007\n",
      "Epoch 262/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1297 - val_loss: 8.1171\n",
      "Epoch 263/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9408 - val_loss: 8.0196\n",
      "Epoch 264/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1976 - val_loss: 7.6798\n",
      "Epoch 265/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2244 - val_loss: 8.0293\n",
      "Epoch 266/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0602 - val_loss: 7.7349\n",
      "Epoch 267/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2211 - val_loss: 7.4058\n",
      "Epoch 268/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1145 - val_loss: 7.7649\n",
      "Epoch 269/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7415 - val_loss: 7.9375\n",
      "Epoch 270/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1098 - val_loss: 9.4987\n",
      "Epoch 271/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3416 - val_loss: 7.9472\n",
      "Epoch 272/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6535 - val_loss: 8.1539\n",
      "Epoch 273/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8564 - val_loss: 7.7816\n",
      "Epoch 274/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8088 - val_loss: 7.6661\n",
      "Epoch 275/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4098 - val_loss: 7.5723\n",
      "Epoch 276/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9488 - val_loss: 7.5198\n",
      "Epoch 277/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1438 - val_loss: 7.6405\n",
      "Epoch 278/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8048 - val_loss: 7.5665\n",
      "Epoch 279/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0123 - val_loss: 7.6301\n",
      "Epoch 280/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.1215 - val_loss: 8.3107\n",
      "Epoch 281/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4214 - val_loss: 8.0924\n",
      "Epoch 282/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1898 - val_loss: 7.6370\n",
      "Epoch 283/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9608 - val_loss: 7.4472\n",
      "Epoch 284/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3002 - val_loss: 7.5224\n",
      "Epoch 285/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9393 - val_loss: 7.5280\n",
      "Epoch 286/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1691 - val_loss: 7.8340\n",
      "Epoch 287/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9264 - val_loss: 7.4398\n",
      "Epoch 288/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8795 - val_loss: 7.7018\n",
      "Epoch 289/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9663 - val_loss: 7.8318\n",
      "Epoch 290/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9541 - val_loss: 7.8392\n",
      "Epoch 291/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1421 - val_loss: 7.4473\n",
      "Epoch 292/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9260 - val_loss: 7.7405\n",
      "Epoch 293/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1407 - val_loss: 7.4876\n",
      "Epoch 294/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8728 - val_loss: 7.9026\n",
      "Epoch 295/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9251 - val_loss: 8.6878\n",
      "Epoch 296/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5028 - val_loss: 8.0278\n",
      "Epoch 297/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8959 - val_loss: 7.8901\n",
      "Epoch 298/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0167 - val_loss: 7.9778\n",
      "Epoch 299/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8648 - val_loss: 8.2366\n",
      "Epoch 300/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9258 - val_loss: 8.3036\n",
      "Epoch 301/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8609 - val_loss: 8.7887\n",
      "Epoch 302/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5582 - val_loss: 8.0391\n",
      "Epoch 303/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9952 - val_loss: 7.8113\n",
      "Epoch 304/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2705 - val_loss: 8.8420\n",
      "Epoch 305/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9142 - val_loss: 7.7504\n",
      "Epoch 306/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7218 - val_loss: 8.3014\n",
      "Epoch 307/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9912 - val_loss: 7.8405\n",
      "Epoch 308/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8556 - val_loss: 7.5764\n",
      "Epoch 309/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5606 - val_loss: 7.6772\n",
      "Epoch 310/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2984 - val_loss: 7.6068\n",
      "Epoch 311/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9430 - val_loss: 7.3607\n",
      "Epoch 312/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9755 - val_loss: 9.1226\n",
      "Epoch 313/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7464 - val_loss: 7.4943\n",
      "Epoch 314/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7918 - val_loss: 7.6393\n",
      "Epoch 315/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8066 - val_loss: 8.2861\n",
      "Epoch 316/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1539 - val_loss: 7.5233\n",
      "Epoch 317/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1766 - val_loss: 7.4305\n",
      "Epoch 318/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.6456 - val_loss: 8.5802\n",
      "Epoch 319/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7826 - val_loss: 7.6499\n",
      "Epoch 320/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7573 - val_loss: 7.9183\n",
      "Epoch 321/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1294 - val_loss: 7.9332\n",
      "Epoch 322/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9308 - val_loss: 7.4817\n",
      "Epoch 323/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1085 - val_loss: 7.6201\n",
      "Epoch 324/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6244 - val_loss: 7.3814\n",
      "Epoch 325/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0765 - val_loss: 7.6257\n",
      "Epoch 326/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0192 - val_loss: 8.6621\n",
      "Epoch 327/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8219 - val_loss: 7.5655\n",
      "Epoch 328/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9030 - val_loss: 7.4837\n",
      "Epoch 329/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8564 - val_loss: 7.4833\n",
      "Epoch 330/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9233 - val_loss: 8.5659\n",
      "Epoch 331/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.7783 - val_loss: 7.7321\n",
      "Epoch 332/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8488 - val_loss: 7.6516\n",
      "Epoch 333/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.8037 - val_loss: 8.0030\n",
      "Epoch 334/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9684 - val_loss: 7.6722\n",
      "Epoch 335/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8259 - val_loss: 7.6625\n",
      "Epoch 336/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7791 - val_loss: 7.6490\n",
      "Epoch 337/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8610 - val_loss: 8.3054\n",
      "Epoch 338/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1480 - val_loss: 8.0968\n",
      "Epoch 339/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0512 - val_loss: 7.5823\n",
      "Epoch 340/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3634 - val_loss: 8.6081\n",
      "Epoch 341/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7320 - val_loss: 7.6679\n",
      "Epoch 342/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4353 - val_loss: 8.1585\n",
      "Epoch 343/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2654 - val_loss: 7.9354\n",
      "Epoch 344/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9578 - val_loss: 7.6559\n",
      "Epoch 345/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8509 - val_loss: 7.4419\n",
      "Epoch 346/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1765 - val_loss: 9.4590\n",
      "Epoch 347/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.6120 - val_loss: 7.4189\n",
      "Epoch 348/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.7012 - val_loss: 7.9779\n",
      "Epoch 349/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1150 - val_loss: 7.7411\n",
      "Epoch 350/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7415 - val_loss: 7.5346\n",
      "Epoch 351/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7195 - val_loss: 7.5991\n",
      "Epoch 352/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.6858 - val_loss: 8.2000\n",
      "Epoch 353/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9562 - val_loss: 7.6060\n",
      "Epoch 354/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7891 - val_loss: 7.3682\n",
      "Epoch 355/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7852 - val_loss: 8.1494\n",
      "Epoch 356/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9710 - val_loss: 8.4012\n",
      "Epoch 357/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1508 - val_loss: 7.6854\n",
      "Epoch 358/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6806 - val_loss: 7.5850\n",
      "Epoch 359/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9557 - val_loss: 7.46133\n",
      "Epoch 360/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7843 - val_loss: 7.5838\n",
      "Epoch 361/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0061 - val_loss: 7.3410\n",
      "Epoch 362/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4320 - val_loss: 8.5600\n",
      "Epoch 363/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6135 - val_loss: 8.3645\n",
      "Epoch 364/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8326 - val_loss: 7.1936\n",
      "Epoch 365/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7430 - val_loss: 8.6627\n",
      "Epoch 366/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7106 - val_loss: 7.5480\n",
      "Epoch 367/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7743 - val_loss: 8.4512\n",
      "Epoch 368/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7426 - val_loss: 7.5936\n",
      "Epoch 369/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9055 - val_loss: 7.5371\n",
      "Epoch 370/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9209 - val_loss: 7.1651\n",
      "Epoch 371/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7197 - val_loss: 7.6215\n",
      "Epoch 372/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8000 - val_loss: 8.4177\n",
      "Epoch 373/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9623 - val_loss: 7.7684\n",
      "Epoch 374/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0201 - val_loss: 8.3314\n",
      "Epoch 375/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9617 - val_loss: 8.1583\n",
      "Epoch 376/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9367 - val_loss: 7.2701\n",
      "Epoch 377/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5985 - val_loss: 7.4144\n",
      "Epoch 378/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7944 - val_loss: 7.6416\n",
      "Epoch 379/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7966 - val_loss: 7.9726\n",
      "Epoch 380/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4668 - val_loss: 7.5090\n",
      "Epoch 381/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6387 - val_loss: 7.8077\n",
      "Epoch 382/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6276 - val_loss: 7.4664\n",
      "Epoch 383/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7729 - val_loss: 7.7795\n",
      "Epoch 384/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3688 - val_loss: 7.8581\n",
      "Epoch 385/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8401 - val_loss: 7.5128\n",
      "Epoch 386/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1757 - val_loss: 8.0101\n",
      "Epoch 387/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2701 - val_loss: 8.0781\n",
      "Epoch 388/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7875 - val_loss: 7.6082\n",
      "Epoch 389/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5968 - val_loss: 7.4145\n",
      "Epoch 390/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5888 - val_loss: 7.6881\n",
      "Epoch 391/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6730 - val_loss: 7.3818\n",
      "Epoch 392/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0136 - val_loss: 7.2156\n",
      "Epoch 393/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8253 - val_loss: 7.9066\n",
      "Epoch 394/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8223 - val_loss: 8.2650\n",
      "Epoch 395/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8399 - val_loss: 7.5482\n",
      "Epoch 396/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1596 - val_loss: 8.2026\n",
      "Epoch 397/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9469 - val_loss: 7.8823\n",
      "Epoch 398/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7272 - val_loss: 7.8950\n",
      "Epoch 399/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6708 - val_loss: 7.4599\n",
      "Epoch 400/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8623 - val_loss: 7.9038\n",
      "Epoch 401/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9371 - val_loss: 7.5520\n",
      "Epoch 402/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5503 - val_loss: 7.6946\n",
      "Epoch 403/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7462 - val_loss: 8.0187\n",
      "Epoch 404/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0175 - val_loss: 7.5979\n",
      "Epoch 405/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5517 - val_loss: 7.7473\n",
      "Epoch 406/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5813 - val_loss: 7.7374\n",
      "Epoch 407/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6331 - val_loss: 7.5551\n",
      "Epoch 408/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7517 - val_loss: 7.7843\n",
      "Epoch 409/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5160 - val_loss: 7.3245\n",
      "Epoch 410/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9658 - val_loss: 8.4624\n",
      "Epoch 411/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7614 - val_loss: 7.6542\n",
      "Epoch 412/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6276 - val_loss: 7.5384\n",
      "Epoch 413/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4376 - val_loss: 7.3604\n",
      "Epoch 414/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4784 - val_loss: 7.2946\n",
      "Epoch 415/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9063 - val_loss: 7.3689\n",
      "Epoch 416/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4519 - val_loss: 7.4421\n",
      "Epoch 417/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4737 - val_loss: 7.3438\n",
      "Epoch 418/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0468 - val_loss: 7.9606\n",
      "Epoch 419/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6483 - val_loss: 7.6653\n",
      "Epoch 420/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5787 - val_loss: 7.2965\n",
      "Epoch 421/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5320 - val_loss: 7.4442\n",
      "Epoch 422/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6969 - val_loss: 7.7019\n",
      "Epoch 423/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7799 - val_loss: 7.6801\n",
      "Epoch 424/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8096 - val_loss: 7.4476\n",
      "Epoch 425/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5149 - val_loss: 7.7163\n",
      "Epoch 426/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8309 - val_loss: 7.6689\n",
      "Epoch 427/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6278 - val_loss: 7.5835\n",
      "Epoch 428/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8345 - val_loss: 7.4267\n",
      "Epoch 429/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5869 - val_loss: 7.4462\n",
      "Epoch 430/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5069 - val_loss: 7.6783\n",
      "Epoch 431/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3400 - val_loss: 8.1655\n",
      "Epoch 432/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5036 - val_loss: 7.7754\n",
      "Epoch 433/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5066 - val_loss: 7.4378\n",
      "Epoch 434/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5963 - val_loss: 7.5317\n",
      "Epoch 435/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0749 - val_loss: 7.5538\n",
      "Epoch 436/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9675 - val_loss: 7.2722\n",
      "Epoch 437/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4587 - val_loss: 8.0243\n",
      "Epoch 438/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7755 - val_loss: 7.2848\n",
      "Epoch 439/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7506 - val_loss: 7.4244\n",
      "Epoch 440/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.968 - 0s 4ms/step - loss: 6.5582 - val_loss: 7.4176\n",
      "Epoch 441/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5921 - val_loss: 7.3061\n",
      "Epoch 442/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9138 - val_loss: 7.5316\n",
      "Epoch 443/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8590 - val_loss: 7.4382\n",
      "Epoch 444/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5000 - val_loss: 8.9977\n",
      "Epoch 445/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2185 - val_loss: 7.6555\n",
      "Epoch 446/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9352 - val_loss: 7.3003\n",
      "Epoch 447/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5540 - val_loss: 7.2209\n",
      "Epoch 448/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4353 - val_loss: 7.2329\n",
      "Epoch 449/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6066 - val_loss: 7.5437\n",
      "Epoch 450/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6676 - val_loss: 7.3896\n",
      "Epoch 451/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6628 - val_loss: 7.2983\n",
      "Epoch 452/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5848 - val_loss: 7.3591\n",
      "Epoch 453/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5977 - val_loss: 7.4050\n",
      "Epoch 454/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5758 - val_loss: 7.5440\n",
      "Epoch 455/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6863 - val_loss: 7.2507\n",
      "Epoch 456/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7958 - val_loss: 7.2380\n",
      "Epoch 457/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5618 - val_loss: 8.4679\n",
      "Epoch 458/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5862 - val_loss: 8.0517\n",
      "Epoch 459/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4895 - val_loss: 7.0140\n",
      "Epoch 460/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9835 - val_loss: 7.8413\n",
      "Epoch 461/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.0244 - val_loss: 7.0980\n",
      "Epoch 462/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9296 - val_loss: 7.6220\n",
      "Epoch 463/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6973 - val_loss: 7.5865\n",
      "Epoch 464/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6830 - val_loss: 8.1730\n",
      "Epoch 465/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2165 - val_loss: 7.3152\n",
      "Epoch 466/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3925 - val_loss: 7.4248\n",
      "Epoch 467/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8254 - val_loss: 7.9427\n",
      "Epoch 468/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3955 - val_loss: 7.1080\n",
      "Epoch 469/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9054 - val_loss: 8.1801\n",
      "Epoch 470/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0390 - val_loss: 7.5212\n",
      "Epoch 471/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4289 - val_loss: 9.0582\n",
      "Epoch 472/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8369 - val_loss: 8.1996\n",
      "Epoch 473/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9989 - val_loss: 7.3425\n",
      "Epoch 474/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5658 - val_loss: 8.5456\n",
      "Epoch 475/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.0213 - val_loss: 7.3375\n",
      "Epoch 476/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6274 - val_loss: 8.7326\n",
      "Epoch 477/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8283 - val_loss: 7.7735\n",
      "Epoch 478/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0059 - val_loss: 7.5639\n",
      "Epoch 479/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8781 - val_loss: 9.6508\n",
      "Epoch 480/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8005 - val_loss: 7.2156\n",
      "Epoch 481/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4670 - val_loss: 7.9030\n",
      "Epoch 482/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4335 - val_loss: 7.2993\n",
      "Epoch 483/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8638 - val_loss: 7.1566\n",
      "Epoch 484/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6779 - val_loss: 7.7332\n",
      "Epoch 485/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7355 - val_loss: 7.7518\n",
      "Epoch 486/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5726 - val_loss: 7.5772\n",
      "Epoch 487/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4429 - val_loss: 7.6795\n",
      "Epoch 488/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3799 - val_loss: 7.2020\n",
      "Epoch 489/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3532 - val_loss: 7.4633\n",
      "Epoch 490/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5879 - val_loss: 7.4826\n",
      "Epoch 491/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5747 - val_loss: 8.5654\n",
      "Epoch 492/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0684 - val_loss: 7.5631\n",
      "Epoch 493/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6916 - val_loss: 7.3358\n",
      "Epoch 494/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4692 - val_loss: 7.2585\n",
      "Epoch 495/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4674 - val_loss: 7.4738\n",
      "Epoch 496/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5069 - val_loss: 7.5853\n",
      "Epoch 497/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5694 - val_loss: 7.0956\n",
      "Epoch 498/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4356 - val_loss: 7.7417\n",
      "Epoch 499/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8664 - val_loss: 7.1132\n",
      "Epoch 500/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4040 - val_loss: 9.36208\n",
      "Epoch 501/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5167 - val_loss: 9.2464\n",
      "Epoch 502/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0111 - val_loss: 7.0822\n",
      "Epoch 503/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8217 - val_loss: 7.1054\n",
      "Epoch 504/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3420 - val_loss: 7.4261\n",
      "Epoch 505/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.579 - 0s 3ms/step - loss: 6.3941 - val_loss: 7.2723\n",
      "Epoch 506/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8360 - val_loss: 7.9564\n",
      "Epoch 507/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4498 - val_loss: 7.1876\n",
      "Epoch 508/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7362 - val_loss: 11.8730\n",
      "Epoch 509/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9956 - val_loss: 6.9616\n",
      "Epoch 510/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5459 - val_loss: 7.6736\n",
      "Epoch 511/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3251 - val_loss: 7.3967\n",
      "Epoch 512/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8286 - val_loss: 7.5723\n",
      "Epoch 513/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5080 - val_loss: 7.1418\n",
      "Epoch 514/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3542 - val_loss: 7.1535\n",
      "Epoch 515/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3010 - val_loss: 7.1843\n",
      "Epoch 516/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5699 - val_loss: 7.5678\n",
      "Epoch 517/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.3976 - val_loss: 7.3804\n",
      "Epoch 518/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2906 - val_loss: 8.7323\n",
      "Epoch 519/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8501 - val_loss: 7.5975\n",
      "Epoch 520/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5481 - val_loss: 7.8879\n",
      "Epoch 521/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9237 - val_loss: 8.3709\n",
      "Epoch 522/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6365 - val_loss: 8.1294\n",
      "Epoch 523/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3860 - val_loss: 7.3514\n",
      "Epoch 524/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9489 - val_loss: 8.9428\n",
      "Epoch 525/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4740 - val_loss: 7.9970\n",
      "Epoch 526/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8463 - val_loss: 8.1906\n",
      "Epoch 527/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2120 - val_loss: 7.7591\n",
      "Epoch 528/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5148 - val_loss: 7.9420\n",
      "Epoch 529/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7518 - val_loss: 7.8124\n",
      "Epoch 530/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2911 - val_loss: 7.1111\n",
      "Epoch 531/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5218 - val_loss: 7.7147\n",
      "Epoch 532/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4594 - val_loss: 7.5233\n",
      "Epoch 533/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4802 - val_loss: 7.3193\n",
      "Epoch 534/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2987 - val_loss: 7.1691\n",
      "Epoch 535/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4501 - val_loss: 7.1552\n",
      "Epoch 536/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3830 - val_loss: 8.5232\n",
      "Epoch 537/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8657 - val_loss: 7.1225\n",
      "Epoch 538/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3705 - val_loss: 7.4130\n",
      "Epoch 539/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2127 - val_loss: 8.0343\n",
      "Epoch 540/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3271 - val_loss: 7.7128\n",
      "Epoch 541/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3964 - val_loss: 7.4707\n",
      "Epoch 542/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1962 - val_loss: 7.8131\n",
      "Epoch 543/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4218 - val_loss: 7.7531\n",
      "Epoch 544/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.3484 - val_loss: 7.0668\n",
      "Epoch 545/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1837 - val_loss: 7.2880\n",
      "Epoch 546/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2933 - val_loss: 7.4412\n",
      "Epoch 547/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0577 - val_loss: 7.2598\n",
      "Epoch 548/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6748 - val_loss: 7.7349\n",
      "Epoch 549/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6018 - val_loss: 7.2132\n",
      "Epoch 550/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9737 - val_loss: 7.9199\n",
      "Epoch 551/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.4665 - val_loss: 7.5573\n",
      "Epoch 552/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9461 - val_loss: 7.2306\n",
      "Epoch 553/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2071 - val_loss: 7.1747\n",
      "Epoch 554/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2113 - val_loss: 7.3731\n",
      "Epoch 555/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7075 - val_loss: 7.4684\n",
      "Epoch 556/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1176 - val_loss: 7.3762\n",
      "Epoch 557/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5268 - val_loss: 7.5948\n",
      "Epoch 558/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6561 - val_loss: 7.8071\n",
      "Epoch 559/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.4431 - val_loss: 6.8593\n",
      "Epoch 560/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 6.5632 - val_loss: 7.3088\n",
      "Epoch 561/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.3318 - val_loss: 7.9877\n",
      "Epoch 562/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2923 - val_loss: 7.7577\n",
      "Epoch 563/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6270 - val_loss: 7.7409\n",
      "Epoch 564/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5384 - val_loss: 7.3919\n",
      "Epoch 565/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8230 - val_loss: 7.3261\n",
      "Epoch 566/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7082 - val_loss: 7.2409\n",
      "Epoch 567/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1544 - val_loss: 7.0960\n",
      "Epoch 568/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9908 - val_loss: 8.2951\n",
      "Epoch 569/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2384 - val_loss: 7.4307\n",
      "Epoch 570/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4496 - val_loss: 8.9933\n",
      "Epoch 571/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3959 - val_loss: 7.4971\n",
      "Epoch 572/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3573 - val_loss: 7.2629\n",
      "Epoch 573/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.4484 - val_loss: 7.3305\n",
      "Epoch 574/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.4578 - val_loss: 7.0375\n",
      "Epoch 575/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.3621 - val_loss: 7.2418\n",
      "Epoch 576/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1973 - val_loss: 7.2856\n",
      "Epoch 577/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2888 - val_loss: 7.4035\n",
      "Epoch 578/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2658 - val_loss: 7.7136\n",
      "Epoch 579/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7847 - val_loss: 7.1963\n",
      "Epoch 580/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2776 - val_loss: 7.1657\n",
      "Epoch 581/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2263 - val_loss: 7.2579\n",
      "Epoch 582/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6436 - val_loss: 7.5459\n",
      "Epoch 583/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9065 - val_loss: 7.4230\n",
      "Epoch 584/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2457 - val_loss: 7.6201\n",
      "Epoch 585/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2091 - val_loss: 7.6945\n",
      "Epoch 586/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.6130 - val_loss: 7.5896\n",
      "Epoch 587/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4885 - val_loss: 6.9090\n",
      "Epoch 588/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6082 - val_loss: 8.1180\n",
      "Epoch 589/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4137 - val_loss: 7.5827\n",
      "Epoch 590/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1354 - val_loss: 7.3823\n",
      "Epoch 591/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3913 - val_loss: 7.6168\n",
      "Epoch 592/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1858 - val_loss: 7.5275\n",
      "Epoch 593/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3483 - val_loss: 8.0136\n",
      "Epoch 594/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2692 - val_loss: 7.3302\n",
      "Epoch 595/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3421 - val_loss: 7.3195\n",
      "Epoch 596/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8924 - val_loss: 7.9380\n",
      "Epoch 597/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8369 - val_loss: 7.3943\n",
      "Epoch 598/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7282 - val_loss: 7.5790\n",
      "Epoch 599/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1262 - val_loss: 7.6313\n",
      "Epoch 600/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3524 - val_loss: 9.5737\n",
      "Epoch 601/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3028 - val_loss: 7.1454\n",
      "Epoch 602/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1821 - val_loss: 7.7175\n",
      "Epoch 603/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0655 - val_loss: 7.8684\n",
      "Epoch 604/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1262 - val_loss: 7.6313\n",
      "Epoch 605/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2957 - val_loss: 7.6219\n",
      "Epoch 606/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7077 - val_loss: 6.9926\n",
      "Epoch 607/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7106 - val_loss: 8.0267\n",
      "Epoch 608/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5437 - val_loss: 7.5284\n",
      "Epoch 609/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2095 - val_loss: 7.4422\n",
      "Epoch 610/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7283 - val_loss: 7.5196\n",
      "Epoch 611/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2685 - val_loss: 8.1574\n",
      "Epoch 612/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5252 - val_loss: 7.1550\n",
      "Epoch 613/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2242 - val_loss: 7.5053\n",
      "Epoch 614/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6123 - val_loss: 7.2536\n",
      "Epoch 615/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9332 - val_loss: 8.2049\n",
      "Epoch 616/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1296 - val_loss: 7.7224\n",
      "Epoch 617/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5087 - val_loss: 7.3995\n",
      "Epoch 618/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3193 - val_loss: 7.1357\n",
      "Epoch 619/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0961 - val_loss: 7.6215\n",
      "Epoch 620/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1415 - val_loss: 7.4797\n",
      "Epoch 621/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2385 - val_loss: 8.7901\n",
      "Epoch 622/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0567 - val_loss: 7.1348\n",
      "Epoch 623/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5222 - val_loss: 8.1202\n",
      "Epoch 624/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3764 - val_loss: 7.2988\n",
      "Epoch 625/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4916 - val_loss: 7.1355\n",
      "Epoch 626/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2972 - val_loss: 8.5873\n",
      "Epoch 627/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9753 - val_loss: 6.9632\n",
      "Epoch 628/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9874 - val_loss: 7.6321\n",
      "Epoch 629/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5825 - val_loss: 8.3075\n",
      "Epoch 630/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.8754 - val_loss: 7.3469\n",
      "Epoch 631/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2087 - val_loss: 7.9358\n",
      "Epoch 632/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3362 - val_loss: 7.1288\n",
      "Epoch 633/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6852 - val_loss: 8.7668\n",
      "Epoch 634/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1843 - val_loss: 8.1715\n",
      "Epoch 635/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2871 - val_loss: 7.0053\n",
      "Epoch 636/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0810 - val_loss: 6.9924\n",
      "Epoch 637/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7283 - val_loss: 8.2623\n",
      "Epoch 638/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2701 - val_loss: 7.2320\n",
      "Epoch 639/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4377 - val_loss: 7.0878\n",
      "Epoch 640/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3970 - val_loss: 7.6323\n",
      "Epoch 641/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6002 - val_loss: 7.1911\n",
      "Epoch 642/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2871 - val_loss: 8.2996\n",
      "Epoch 643/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3292 - val_loss: 7.6279\n",
      "Epoch 644/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0305 - val_loss: 7.5041\n",
      "Epoch 645/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2049 - val_loss: 8.1856\n",
      "Epoch 646/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.8937 - 0s 4ms/step - loss: 6.2781 - val_loss: 7.0167\n",
      "Epoch 647/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9945 - val_loss: 7.4081\n",
      "Epoch 648/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4364 - val_loss: 7.0475\n",
      "Epoch 649/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6441 - val_loss: 6.6807\n",
      "Epoch 650/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.6265 - val_loss: 7.5080\n",
      "Epoch 651/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4594 - val_loss: 7.1543\n",
      "Epoch 652/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4457 - val_loss: 7.7653\n",
      "Epoch 653/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0600 - val_loss: 6.8900\n",
      "Epoch 654/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3187 - val_loss: 7.0509\n",
      "Epoch 655/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.0238 - val_loss: 7.0578\n",
      "Epoch 656/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9069 - val_loss: 7.1911\n",
      "Epoch 657/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.7311 - val_loss: 7.6970\n",
      "Epoch 658/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0618 - val_loss: 7.1281\n",
      "Epoch 659/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3454 - val_loss: 7.3023\n",
      "Epoch 660/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1003 - val_loss: 7.0409\n",
      "Epoch 661/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7105 - val_loss: 7.9569\n",
      "Epoch 662/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4734 - val_loss: 8.9610\n",
      "Epoch 663/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0464 - val_loss: 6.9679\n",
      "Epoch 664/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2763 - val_loss: 7.0272\n",
      "Epoch 665/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1206 - val_loss: 8.4724\n",
      "Epoch 666/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6156 - val_loss: 7.2846\n",
      "Epoch 667/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2761 - val_loss: 7.2765\n",
      "Epoch 668/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1538 - val_loss: 8.0084\n",
      "Epoch 669/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0845 - val_loss: 7.6154\n",
      "Epoch 670/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1649 - val_loss: 7.1815\n",
      "Epoch 671/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1901 - val_loss: 8.6621\n",
      "Epoch 672/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5769 - val_loss: 7.0363\n",
      "Epoch 673/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3549 - val_loss: 6.7717\n",
      "Epoch 674/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1061 - val_loss: 7.1768\n",
      "Epoch 675/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0274 - val_loss: 7.2771\n",
      "Epoch 676/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3113 - val_loss: 7.0708\n",
      "Epoch 677/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1197 - val_loss: 7.3367\n",
      "Epoch 678/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2243 - val_loss: 7.2336\n",
      "Epoch 679/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1695 - val_loss: 7.0447\n",
      "Epoch 680/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9743 - val_loss: 8.2110\n",
      "Epoch 681/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2619 - val_loss: 6.9882\n",
      "Epoch 682/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2811 - val_loss: 7.3875\n",
      "Epoch 683/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2384 - val_loss: 7.3074\n",
      "Epoch 684/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3849 - val_loss: 7.3314\n",
      "Epoch 685/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1233 - val_loss: 7.8503\n",
      "Epoch 686/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1483 - val_loss: 6.9223\n",
      "Epoch 687/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9527 - val_loss: 8.1191\n",
      "Epoch 688/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9807 - val_loss: 8.7359\n",
      "Epoch 689/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0909 - val_loss: 7.4119\n",
      "Epoch 690/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1096 - val_loss: 6.9172\n",
      "Epoch 691/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1068 - val_loss: 8.7545\n",
      "Epoch 692/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4343 - val_loss: 7.4639\n",
      "Epoch 693/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0313 - val_loss: 7.3350\n",
      "Epoch 694/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9385 - val_loss: 6.7942\n",
      "Epoch 695/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1180 - val_loss: 7.1139\n",
      "Epoch 696/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9989 - val_loss: 7.1773\n",
      "Epoch 697/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3194 - val_loss: 7.4178\n",
      "Epoch 698/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1456 - val_loss: 7.5584\n",
      "Epoch 699/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1837 - val_loss: 7.3823\n",
      "Epoch 700/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4404 - val_loss: 7.2216\n",
      "Epoch 701/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1629 - val_loss: 7.7715\n",
      "Epoch 702/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9156 - val_loss: 7.2630\n",
      "Epoch 703/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8913 - val_loss: 7.3211\n",
      "Epoch 704/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1658 - val_loss: 7.1657\n",
      "Epoch 705/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0426 - val_loss: 6.9455\n",
      "Epoch 706/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1944 - val_loss: 7.0655\n",
      "Epoch 707/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1916 - val_loss: 7.0945\n",
      "Epoch 708/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0844 - val_loss: 7.3796\n",
      "Epoch 709/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7959 - val_loss: 6.9735\n",
      "Epoch 710/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8855 - val_loss: 7.0880\n",
      "Epoch 711/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9922 - val_loss: 7.9714\n",
      "Epoch 712/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8250 - val_loss: 7.0788\n",
      "Epoch 713/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8777 - val_loss: 7.1795\n",
      "Epoch 714/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1436 - val_loss: 7.6783\n",
      "Epoch 715/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9797 - val_loss: 6.8527\n",
      "Epoch 716/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1544 - val_loss: 6.9383\n",
      "Epoch 717/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2172 - val_loss: 7.2974\n",
      "Epoch 718/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9507 - val_loss: 7.4457\n",
      "Epoch 719/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9528 - val_loss: 6.9769\n",
      "Epoch 720/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8207 - val_loss: 6.8070\n",
      "Epoch 721/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3258 - val_loss: 7.1028\n",
      "Epoch 722/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1489 - val_loss: 7.8578\n",
      "Epoch 723/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5989 - val_loss: 7.3181\n",
      "Epoch 724/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1668 - val_loss: 7.4952\n",
      "Epoch 725/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8425 - val_loss: 7.0126\n",
      "Epoch 726/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0237 - val_loss: 7.1959\n",
      "Epoch 727/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.0797 - val_loss: 6.9723\n",
      "Epoch 728/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0450 - val_loss: 7.7922\n",
      "Epoch 729/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0860 - val_loss: 6.8622\n",
      "Epoch 730/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3921 - val_loss: 7.0549\n",
      "Epoch 731/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4857 - val_loss: 7.1091\n",
      "Epoch 732/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8810 - val_loss: 7.5772\n",
      "Epoch 733/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9232 - val_loss: 7.6872\n",
      "Epoch 734/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4578 - val_loss: 6.9608\n",
      "Epoch 735/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8498 - val_loss: 7.3098\n",
      "Epoch 736/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9012 - val_loss: 7.0564\n",
      "Epoch 737/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9116 - val_loss: 6.6966\n",
      "Epoch 738/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8632 - val_loss: 7.3437\n",
      "Epoch 739/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2666 - val_loss: 7.5769\n",
      "Epoch 740/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8873 - val_loss: 6.7393\n",
      "Epoch 741/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9965 - val_loss: 7.4358\n",
      "Epoch 742/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8955 - val_loss: 7.0722\n",
      "Epoch 743/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8467 - val_loss: 6.9592\n",
      "Epoch 744/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1009 - val_loss: 7.3074\n",
      "Epoch 745/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9769 - val_loss: 7.2323\n",
      "Epoch 746/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1963 - val_loss: 8.6052\n",
      "Epoch 747/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4090 - val_loss: 7.3286\n",
      "Epoch 748/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2853 - val_loss: 8.1344\n",
      "Epoch 749/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1565 - val_loss: 7.1099\n",
      "Epoch 750/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0369 - val_loss: 7.9261\n",
      "Epoch 751/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3398 - val_loss: 6.8150\n",
      "Epoch 752/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0239 - val_loss: 7.1401\n",
      "Epoch 753/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2336 - val_loss: 6.7000\n",
      "Epoch 754/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2279 - val_loss: 6.7934\n",
      "Epoch 755/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9138 - val_loss: 7.2973\n",
      "Epoch 756/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7550 - val_loss: 8.2566\n",
      "Epoch 757/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3953 - val_loss: 6.9661\n",
      "Epoch 758/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1482 - val_loss: 8.1276\n",
      "Epoch 759/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.7681 - val_loss: 6.6029\n",
      "Epoch 760/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9719 - val_loss: 6.8101\n",
      "Epoch 761/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0109 - val_loss: 6.9256\n",
      "Epoch 762/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7835 - val_loss: 6.8789\n",
      "Epoch 763/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5949 - val_loss: 6.8872\n",
      "Epoch 764/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7527 - val_loss: 6.9445\n",
      "Epoch 765/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8810 - val_loss: 7.2474\n",
      "Epoch 766/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7974 - val_loss: 6.6615\n",
      "Epoch 767/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0244 - val_loss: 6.9067\n",
      "Epoch 768/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9433 - val_loss: 6.9977\n",
      "Epoch 769/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9658 - val_loss: 6.8480\n",
      "Epoch 770/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9096 - val_loss: 6.9636\n",
      "Epoch 771/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1554 - val_loss: 6.7978\n",
      "Epoch 772/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7404 - val_loss: 7.0608\n",
      "Epoch 773/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8130 - val_loss: 6.9416\n",
      "Epoch 774/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8278 - val_loss: 7.1662\n",
      "Epoch 775/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0784 - val_loss: 6.6945\n",
      "Epoch 776/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8078 - val_loss: 6.7559\n",
      "Epoch 777/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9683 - val_loss: 7.2549\n",
      "Epoch 778/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0923 - val_loss: 7.0870\n",
      "Epoch 779/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9633 - val_loss: 7.3165\n",
      "Epoch 780/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2423 - val_loss: 6.8090\n",
      "Epoch 781/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9520 - val_loss: 7.7339\n",
      "Epoch 782/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9991 - val_loss: 6.7601\n",
      "Epoch 783/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.4033 - val_loss: 7.2457\n",
      "Epoch 784/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9475 - val_loss: 8.6012\n",
      "Epoch 785/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2044 - val_loss: 6.8702\n",
      "Epoch 786/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8142 - val_loss: 7.0874\n",
      "Epoch 787/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9202 - val_loss: 7.1192\n",
      "Epoch 788/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7344 - val_loss: 6.8499\n",
      "Epoch 789/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7307 - val_loss: 7.7208\n",
      "Epoch 790/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8066 - val_loss: 8.3633\n",
      "Epoch 791/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9715 - val_loss: 6.9032\n",
      "Epoch 792/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.6436 - val_loss: 7.1491\n",
      "Epoch 793/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.7632 - val_loss: 6.6100\n",
      "Epoch 794/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8377 - val_loss: 7.1533\n",
      "Epoch 795/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8439 - val_loss: 6.8438\n",
      "Epoch 796/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9499 - val_loss: 7.1646\n",
      "Epoch 797/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8781 - val_loss: 6.7441\n",
      "Epoch 798/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8913 - val_loss: 6.4119\n",
      "Epoch 799/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.0060 - val_loss: 7.3867\n",
      "Epoch 800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2131 - val_loss: 7.7509\n",
      "Epoch 801/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0119 - val_loss: 6.9652\n",
      "Epoch 802/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9133 - val_loss: 7.5580\n",
      "Epoch 803/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0144 - val_loss: 6.9840\n",
      "Epoch 804/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6484 - val_loss: 6.7947\n",
      "Epoch 805/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4422 - val_loss: 9.0440\n",
      "Epoch 806/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3732 - val_loss: 7.0065\n",
      "Epoch 807/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8531 - val_loss: 7.1720\n",
      "Epoch 808/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8361 - val_loss: 6.8281\n",
      "Epoch 809/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8533 - val_loss: 6.7696\n",
      "Epoch 810/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8458 - val_loss: 6.8202\n",
      "Epoch 811/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1771 - val_loss: 7.3500\n",
      "Epoch 812/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2224 - val_loss: 7.4902\n",
      "Epoch 813/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1319 - val_loss: 8.2558\n",
      "Epoch 814/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0176 - val_loss: 6.9369\n",
      "Epoch 815/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9351 - val_loss: 6.6118\n",
      "Epoch 816/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3954 - val_loss: 7.0157\n",
      "Epoch 817/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7257 - val_loss: 6.8206\n",
      "Epoch 818/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6802 - val_loss: 6.6838\n",
      "Epoch 819/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6199 - val_loss: 6.7071\n",
      "Epoch 820/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5948 - val_loss: 7.0331\n",
      "Epoch 821/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7496 - val_loss: 6.8062\n",
      "Epoch 822/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0040 - val_loss: 6.5469\n",
      "Epoch 823/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7731 - val_loss: 7.4185\n",
      "Epoch 824/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2799 - val_loss: 6.7272\n",
      "Epoch 825/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.560 - 0s 3ms/step - loss: 5.8339 - val_loss: 6.8557\n",
      "Epoch 826/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5513 - val_loss: 6.8406\n",
      "Epoch 827/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7578 - val_loss: 6.7274\n",
      "Epoch 828/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7087 - val_loss: 7.0904\n",
      "Epoch 829/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5277 - val_loss: 6.9335\n",
      "Epoch 830/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8951 - val_loss: 7.3102\n",
      "Epoch 831/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0493 - val_loss: 7.3126\n",
      "Epoch 832/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1028 - val_loss: 7.1617\n",
      "Epoch 833/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8073 - val_loss: 6.8586\n",
      "Epoch 834/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9050 - val_loss: 6.8816\n",
      "Epoch 835/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8612 - val_loss: 7.5778\n",
      "Epoch 836/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9774 - val_loss: 6.5621\n",
      "Epoch 837/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8013 - val_loss: 7.3935\n",
      "Epoch 838/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2226 - val_loss: 7.4506\n",
      "Epoch 839/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9705 - val_loss: 6.8722\n",
      "Epoch 840/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6321 - val_loss: 7.2416\n",
      "Epoch 841/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1075 - val_loss: 7.1354\n",
      "Epoch 842/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0249 - val_loss: 6.7901\n",
      "Epoch 843/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7314 - val_loss: 7.3661\n",
      "Epoch 844/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3181 - val_loss: 7.7307\n",
      "Epoch 845/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8804 - val_loss: 7.0297\n",
      "Epoch 846/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9775 - val_loss: 6.6475\n",
      "Epoch 847/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7429 - val_loss: 6.6419\n",
      "Epoch 848/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6259 - val_loss: 6.8859\n",
      "Epoch 849/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7176 - val_loss: 6.7928\n",
      "Epoch 850/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6400 - val_loss: 6.9080\n",
      "Epoch 851/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5831 - val_loss: 7.3189\n",
      "Epoch 852/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0247 - val_loss: 6.5636\n",
      "Epoch 853/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5729 - val_loss: 6.7477\n",
      "Epoch 854/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6809 - val_loss: 6.8214\n",
      "Epoch 855/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5999 - val_loss: 7.3943\n",
      "Epoch 856/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7823 - val_loss: 6.7570\n",
      "Epoch 857/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8045 - val_loss: 6.8173\n",
      "Epoch 858/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7169 - val_loss: 6.6188\n",
      "Epoch 859/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7467 - val_loss: 6.5336\n",
      "Epoch 860/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6685 - val_loss: 6.8726\n",
      "Epoch 861/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8498 - val_loss: 7.1014\n",
      "Epoch 862/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9536 - val_loss: 6.8453\n",
      "Epoch 863/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9873 - val_loss: 8.2379\n",
      "Epoch 864/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7937 - val_loss: 7.1782\n",
      "Epoch 865/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6280 - val_loss: 6.5646\n",
      "Epoch 866/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1165 - val_loss: 7.9519\n",
      "Epoch 867/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4390 - val_loss: 7.2365\n",
      "Epoch 868/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7083 - val_loss: 6.6937\n",
      "Epoch 869/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7334 - val_loss: 7.4824\n",
      "Epoch 870/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8314 - val_loss: 6.7255\n",
      "Epoch 871/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9897 - val_loss: 7.4293\n",
      "Epoch 872/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0479 - val_loss: 6.5832\n",
      "Epoch 873/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5215 - val_loss: 6.5498\n",
      "Epoch 874/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6439 - val_loss: 6.7097\n",
      "Epoch 875/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4988 - val_loss: 7.0579\n",
      "Epoch 876/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5864 - val_loss: 6.6799\n",
      "Epoch 877/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4759 - val_loss: 6.7245\n",
      "Epoch 878/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4206 - val_loss: 7.6104\n",
      "Epoch 879/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8108 - val_loss: 6.4353\n",
      "Epoch 880/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5861 - val_loss: 6.9619\n",
      "Epoch 881/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5387 - val_loss: 7.7040\n",
      "Epoch 882/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6181 - val_loss: 6.6182\n",
      "Epoch 883/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5553 - val_loss: 6.9908\n",
      "Epoch 884/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5874 - val_loss: 6.8404\n",
      "Epoch 885/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6150 - val_loss: 6.7722\n",
      "Epoch 886/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5114 - val_loss: 6.8929\n",
      "Epoch 887/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6872 - val_loss: 7.1003\n",
      "Epoch 888/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5944 - val_loss: 7.4872\n",
      "Epoch 889/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0686 - val_loss: 6.7388\n",
      "Epoch 890/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8693 - val_loss: 6.8277\n",
      "Epoch 891/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6649 - val_loss: 6.5754\n",
      "Epoch 892/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6290 - val_loss: 7.5246\n",
      "Epoch 893/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5397 - val_loss: 6.5279\n",
      "Epoch 894/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4588 - val_loss: 7.2258\n",
      "Epoch 895/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8909 - val_loss: 6.6295\n",
      "Epoch 896/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6994 - val_loss: 6.9600\n",
      "Epoch 897/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8716 - val_loss: 8.7747\n",
      "Epoch 898/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8667 - val_loss: 7.0212\n",
      "Epoch 899/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8675 - val_loss: 7.2382\n",
      "Epoch 900/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8538 - val_loss: 6.5338\n",
      "Epoch 901/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4783 - val_loss: 6.8517\n",
      "Epoch 902/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5751 - val_loss: 6.8456\n",
      "Epoch 903/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5254 - val_loss: 7.2439\n",
      "Epoch 904/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5278 - val_loss: 7.2359\n",
      "Epoch 905/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7179 - val_loss: 6.8897\n",
      "Epoch 906/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6316 - val_loss: 6.5723\n",
      "Epoch 907/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7060 - val_loss: 7.3798\n",
      "Epoch 908/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6144 - val_loss: 6.6177\n",
      "Epoch 909/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7324 - val_loss: 6.6042\n",
      "Epoch 910/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0892 - val_loss: 6.5400\n",
      "Epoch 911/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4536 - val_loss: 8.4026\n",
      "Epoch 912/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7939 - val_loss: 6.4912\n",
      "Epoch 913/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4268 - val_loss: 6.5633\n",
      "Epoch 914/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4737 - val_loss: 6.5859\n",
      "Epoch 915/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4779 - val_loss: 6.5322\n",
      "Epoch 916/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5024 - val_loss: 6.4897\n",
      "Epoch 917/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.5017 - val_loss: 6.6976\n",
      "Epoch 918/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4113 - val_loss: 6.7243\n",
      "Epoch 919/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3786 - val_loss: 6.9398\n",
      "Epoch 920/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5083 - val_loss: 6.5664\n",
      "Epoch 921/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.6210 - val_loss: 6.7918\n",
      "Epoch 922/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4588 - val_loss: 6.5290\n",
      "Epoch 923/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4793 - val_loss: 6.5309\n",
      "Epoch 924/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4291 - val_loss: 6.5589\n",
      "Epoch 925/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6189 - val_loss: 7.4238\n",
      "Epoch 926/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9163 - val_loss: 6.3949\n",
      "Epoch 927/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5491 - val_loss: 6.9363\n",
      "Epoch 928/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3311 - val_loss: 6.9590\n",
      "Epoch 929/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7474 - val_loss: 6.8963\n",
      "Epoch 930/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4313 - val_loss: 6.8486\n",
      "Epoch 931/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4547 - val_loss: 7.2361\n",
      "Epoch 932/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0998 - val_loss: 7.2026\n",
      "Epoch 933/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7825 - val_loss: 7.9589\n",
      "Epoch 934/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7994 - val_loss: 6.5108\n",
      "Epoch 935/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5037 - val_loss: 7.0102\n",
      "Epoch 936/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0231 - val_loss: 6.7225\n",
      "Epoch 937/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4222 - val_loss: 7.6162\n",
      "Epoch 938/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4860 - val_loss: 6.6514\n",
      "Epoch 939/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6777 - val_loss: 7.1029\n",
      "Epoch 940/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5395 - val_loss: 6.6968\n",
      "Epoch 941/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1112 - val_loss: 6.7406\n",
      "Epoch 942/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7355 - val_loss: 6.6091\n",
      "Epoch 943/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7491 - val_loss: 6.4175\n",
      "Epoch 944/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7522 - val_loss: 6.8698\n",
      "Epoch 945/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8247 - val_loss: 8.0043\n",
      "Epoch 946/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.552 - 0s 5ms/step - loss: 5.4022 - val_loss: 6.5670\n",
      "Epoch 947/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2438 - val_loss: 7.5982\n",
      "Epoch 948/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5837 - val_loss: 7.2688\n",
      "Epoch 949/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3942 - val_loss: 6.8774\n",
      "Epoch 950/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4982 - val_loss: 6.5126\n",
      "Epoch 951/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3114 - val_loss: 6.9542\n",
      "Epoch 952/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4827 - val_loss: 7.0060\n",
      "Epoch 953/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5087 - val_loss: 6.3635\n",
      "Epoch 954/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6514 - val_loss: 6.5863\n",
      "Epoch 955/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4703 - val_loss: 6.6568\n",
      "Epoch 956/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4516 - val_loss: 6.5618\n",
      "Epoch 957/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3003 - val_loss: 6.4809\n",
      "Epoch 958/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2770 - val_loss: 7.1031\n",
      "Epoch 959/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4664 - val_loss: 7.4343\n",
      "Epoch 960/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5689 - val_loss: 6.6459\n",
      "Epoch 961/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6474 - val_loss: 7.6074\n",
      "Epoch 962/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5482 - val_loss: 7.0675\n",
      "Epoch 963/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2620 - val_loss: 6.8784\n",
      "Epoch 964/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3404 - val_loss: 7.6280\n",
      "Epoch 965/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3605 - val_loss: 7.1223\n",
      "Epoch 966/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4044 - val_loss: 6.4257\n",
      "Epoch 967/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1457 - val_loss: 8.0238\n",
      "Epoch 968/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5554 - val_loss: 6.7552\n",
      "Epoch 969/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1915 - val_loss: 6.4129\n",
      "Epoch 970/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.918 - ETA: 0s - loss: 5.319 - 0s 4ms/step - loss: 5.3742 - val_loss: 7.3726\n",
      "Epoch 971/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5346 - val_loss: 6.9656\n",
      "Epoch 972/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2359 - val_loss: 6.8327\n",
      "Epoch 973/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5640 - val_loss: 6.5898\n",
      "Epoch 974/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2122 - val_loss: 6.6624\n",
      "Epoch 975/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3915 - val_loss: 7.0031\n",
      "Epoch 976/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8393 - val_loss: 8.0162\n",
      "Epoch 977/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1499 - val_loss: 6.5751\n",
      "Epoch 978/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5362 - val_loss: 6.9026\n",
      "Epoch 979/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5614 - val_loss: 6.5505\n",
      "Epoch 980/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2392 - val_loss: 6.6849\n",
      "Epoch 981/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2116 - val_loss: 6.4330\n",
      "Epoch 982/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2227 - val_loss: 6.9894\n",
      "Epoch 983/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4309 - val_loss: 6.3802\n",
      "Epoch 984/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3990 - val_loss: 6.6819\n",
      "Epoch 985/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6554 - val_loss: 6.9842\n",
      "Epoch 986/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3471 - val_loss: 6.9259\n",
      "Epoch 987/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1352 - val_loss: 6.8810\n",
      "Epoch 988/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8193 - val_loss: 8.0006\n",
      "Epoch 989/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3363 - val_loss: 6.5372\n",
      "Epoch 990/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1759 - val_loss: 6.7137\n",
      "Epoch 991/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4403 - val_loss: 6.9889\n",
      "Epoch 992/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2986 - val_loss: 7.1548\n",
      "Epoch 993/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1932 - val_loss: 6.3846\n",
      "Epoch 994/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5190 - val_loss: 6.4149\n",
      "Epoch 995/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4430 - val_loss: 7.0369\n",
      "Epoch 996/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5005 - val_loss: 6.9367\n",
      "Epoch 997/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4456 - val_loss: 7.0959\n",
      "Epoch 998/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3310 - val_loss: 7.1938\n",
      "Epoch 999/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3618 - val_loss: 6.5546\n",
      "Epoch 1000/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4104 - val_loss: 6.4910\n",
      "Epoch 1001/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3872 - val_loss: 6.8763\n",
      "Epoch 1002/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5340 - val_loss: 6.7437\n",
      "Epoch 1003/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4335 - val_loss: 6.7201\n",
      "Epoch 1004/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1162 - val_loss: 6.4692\n",
      "Epoch 1005/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2257 - val_loss: 7.9955\n",
      "Epoch 1006/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.6561 - val_loss: 6.7429\n",
      "Epoch 1007/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.1523 - val_loss: 6.7798\n",
      "Epoch 1008/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0383 - val_loss: 7.6809\n",
      "Epoch 1009/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4413 - val_loss: 6.8566\n",
      "Epoch 1010/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1470 - val_loss: 7.2687\n",
      "Epoch 1011/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5579 - val_loss: 7.6177\n",
      "Epoch 1012/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5417 - val_loss: 6.5295\n",
      "Epoch 1013/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8407 - val_loss: 6.8461\n",
      "Epoch 1014/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4550 - val_loss: 7.6971\n",
      "Epoch 1015/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2467 - val_loss: 7.8118\n",
      "Epoch 1016/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1235 - val_loss: 6.8759\n",
      "Epoch 1017/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9109 - val_loss: 9.1239\n",
      "Epoch 1018/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4456 - val_loss: 6.4093\n",
      "Epoch 1019/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.6150 - val_loss: 6.1764\n",
      "Epoch 1020/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2532 - val_loss: 6.6754\n",
      "Epoch 1021/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2285 - val_loss: 6.7253\n",
      "Epoch 1022/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8033 - val_loss: 6.8227\n",
      "Epoch 1023/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3646 - val_loss: 6.5299\n",
      "Epoch 1024/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4250 - val_loss: 6.4936\n",
      "Epoch 1025/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1131 - val_loss: 6.7422\n",
      "Epoch 1026/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1451 - val_loss: 6.4705\n",
      "Epoch 1027/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2752 - val_loss: 7.0761\n",
      "Epoch 1028/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3113 - val_loss: 6.6444\n",
      "Epoch 1029/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1031 - val_loss: 6.6665\n",
      "Epoch 1030/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.2764 - val_loss: 7.1279\n",
      "Epoch 1031/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2324 - val_loss: 6.9360\n",
      "Epoch 1032/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3640 - val_loss: 6.5108\n",
      "Epoch 1033/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0481 - val_loss: 6.5318\n",
      "Epoch 1034/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.1589 - val_loss: 6.5055\n",
      "Epoch 1035/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4817 - val_loss: 7.5651\n",
      "Epoch 1036/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1937 - val_loss: 7.1201\n",
      "Epoch 1037/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5443 - val_loss: 6.5779\n",
      "Epoch 1038/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0253 - val_loss: 6.7068\n",
      "Epoch 1039/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 5.0113 - val_loss: 6.7417\n",
      "Epoch 1040/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3559 - val_loss: 6.8270\n",
      "Epoch 1041/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2997 - val_loss: 6.7249\n",
      "Epoch 1042/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.1254 - val_loss: 6.7327\n",
      "Epoch 1043/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0338 - val_loss: 6.7545\n",
      "Epoch 1044/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2473 - val_loss: 7.1036\n",
      "Epoch 1045/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5280 - val_loss: 6.5664\n",
      "Epoch 1046/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0243 - val_loss: 6.7664\n",
      "Epoch 1047/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2538 - val_loss: 6.4556\n",
      "Epoch 1048/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9440 - val_loss: 7.2093\n",
      "Epoch 1049/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2542 - val_loss: 6.7671\n",
      "Epoch 1050/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1706 - val_loss: 6.6296\n",
      "Epoch 1051/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1201 - val_loss: 6.5851\n",
      "Epoch 1052/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1094 - val_loss: 7.1160\n",
      "Epoch 1053/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3237 - val_loss: 7.3504\n",
      "Epoch 1054/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1782 - val_loss: 6.7275\n",
      "Epoch 1055/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3351 - val_loss: 6.5391\n",
      "Epoch 1056/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9239 - val_loss: 6.4841\n",
      "Epoch 1057/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2281 - val_loss: 7.0872\n",
      "Epoch 1058/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1389 - val_loss: 6.7826\n",
      "Epoch 1059/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2313 - val_loss: 6.0757\n",
      "Epoch 1060/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0561 - val_loss: 6.9991\n",
      "Epoch 1061/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0932 - val_loss: 6.5360\n",
      "Epoch 1062/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5252 - val_loss: 6.7311\n",
      "Epoch 1063/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1326 - val_loss: 6.6890\n",
      "Epoch 1064/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0986 - val_loss: 6.3882\n",
      "Epoch 1065/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1892 - val_loss: 7.0833\n",
      "Epoch 1066/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1477 - val_loss: 7.3111\n",
      "Epoch 1067/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2009 - val_loss: 6.7122\n",
      "Epoch 1068/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1304 - val_loss: 6.8538\n",
      "Epoch 1069/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9006 - val_loss: 7.4218\n",
      "Epoch 1070/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5999 - val_loss: 6.9089\n",
      "Epoch 1071/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0262 - val_loss: 6.6544\n",
      "Epoch 1072/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0026 - val_loss: 6.4067\n",
      "Epoch 1073/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1552 - val_loss: 6.6632\n",
      "Epoch 1074/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9673 - val_loss: 6.8079\n",
      "Epoch 1075/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1293 - val_loss: 7.2446\n",
      "Epoch 1076/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0666 - val_loss: 6.7436\n",
      "Epoch 1077/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1896 - val_loss: 6.8134\n",
      "Epoch 1078/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1131 - val_loss: 6.7743\n",
      "Epoch 1079/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4513 - val_loss: 7.9247\n",
      "Epoch 1080/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9315 - val_loss: 6.4197\n",
      "Epoch 1081/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0046 - val_loss: 7.0011\n",
      "Epoch 1082/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1486 - val_loss: 7.3698\n",
      "Epoch 1083/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2017 - val_loss: 6.4158\n",
      "Epoch 1084/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9970 - val_loss: 7.2978\n",
      "Epoch 1085/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1039 - val_loss: 6.4648\n",
      "Epoch 1086/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7499 - val_loss: 6.9055\n",
      "Epoch 1087/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4943 - val_loss: 7.2017\n",
      "Epoch 1088/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3259 - val_loss: 6.5068\n",
      "Epoch 1089/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4209 - val_loss: 6.6963\n",
      "Epoch 1090/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9045 - val_loss: 8.2688\n",
      "Epoch 1091/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1914 - val_loss: 6.5398\n",
      "Epoch 1092/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9448 - val_loss: 6.8580\n",
      "Epoch 1093/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2114 - val_loss: 6.6443\n",
      "Epoch 1094/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9000 - val_loss: 6.3602\n",
      "Epoch 1095/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8696 - val_loss: 6.6033\n",
      "Epoch 1096/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9493 - val_loss: 7.7953\n",
      "Epoch 1097/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0474 - val_loss: 6.9311\n",
      "Epoch 1098/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8577 - val_loss: 6.8256\n",
      "Epoch 1099/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9632 - val_loss: 6.2175\n",
      "Epoch 1100/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9446 - val_loss: 6.5727\n",
      "Epoch 1101/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8667 - val_loss: 6.1221\n",
      "Epoch 1102/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9438 - val_loss: 6.6719\n",
      "Epoch 1103/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9609 - val_loss: 6.6581\n",
      "Epoch 1104/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1877 - val_loss: 6.7308\n",
      "Epoch 1105/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0334 - val_loss: 7.3015\n",
      "Epoch 1106/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1016 - val_loss: 7.4021\n",
      "Epoch 1107/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1227 - val_loss: 6.5831\n",
      "Epoch 1108/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6376 - val_loss: 8.0617\n",
      "Epoch 1109/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7447 - val_loss: 8.3620\n",
      "Epoch 1110/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0728 - val_loss: 7.0373\n",
      "Epoch 1111/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2905 - val_loss: 7.0094\n",
      "Epoch 1112/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7795 - val_loss: 6.8262\n",
      "Epoch 1113/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9453 - val_loss: 6.9567\n",
      "Epoch 1114/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0230 - val_loss: 6.9439\n",
      "Epoch 1115/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8572 - val_loss: 7.34317\n",
      "Epoch 1116/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9161 - val_loss: 6.3338\n",
      "Epoch 1117/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8647 - val_loss: 6.6084\n",
      "Epoch 1118/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1578 - val_loss: 6.4464\n",
      "Epoch 1119/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8652 - val_loss: 6.9720\n",
      "Epoch 1120/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9171 - val_loss: 6.8307\n",
      "Epoch 1121/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0767 - val_loss: 6.5810\n",
      "Epoch 1122/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6672 - val_loss: 7.6650\n",
      "Epoch 1123/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5895 - val_loss: 6.6876\n",
      "Epoch 1124/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8098 - val_loss: 6.5305\n",
      "Epoch 1125/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8495 - val_loss: 6.7409\n",
      "Epoch 1126/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8508 - val_loss: 7.1885\n",
      "Epoch 1127/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0149 - val_loss: 7.6376\n",
      "Epoch 1128/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0755 - val_loss: 6.8165\n",
      "Epoch 1129/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9673 - val_loss: 6.5588\n",
      "Epoch 1130/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1405 - val_loss: 6.5727\n",
      "Epoch 1131/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0811 - val_loss: 6.7984\n",
      "Epoch 1132/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1665 - val_loss: 7.8450\n",
      "Epoch 1133/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1133 - val_loss: 6.4437\n",
      "Epoch 1134/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9723 - val_loss: 6.5582\n",
      "Epoch 1135/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9023 - val_loss: 7.3416\n",
      "Epoch 1136/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6538 - val_loss: 7.8895\n",
      "Epoch 1137/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8562 - val_loss: 6.3535\n",
      "Epoch 1138/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8208 - val_loss: 7.0489\n",
      "Epoch 1139/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1030 - val_loss: 6.4760\n",
      "Epoch 1140/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0421 - val_loss: 6.7671\n",
      "Epoch 1141/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9304 - val_loss: 6.6015\n",
      "Epoch 1142/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7191 - val_loss: 7.2017\n",
      "Epoch 1143/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9163 - val_loss: 6.5767\n",
      "Epoch 1144/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6427 - val_loss: 6.9455\n",
      "Epoch 1145/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0870 - val_loss: 6.8408\n",
      "Epoch 1146/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0841 - val_loss: 6.8384\n",
      "Epoch 1147/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7172 - val_loss: 6.5473\n",
      "Epoch 1148/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5663 - val_loss: 6.8919\n",
      "Epoch 1149/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8502 - val_loss: 7.3449\n",
      "Epoch 1150/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6553 - val_loss: 6.6542\n",
      "Epoch 1151/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7399 - val_loss: 6.5523\n",
      "Epoch 1152/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6145 - val_loss: 7.3847\n",
      "Epoch 1153/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8068 - val_loss: 6.8176\n",
      "Epoch 1154/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7119 - val_loss: 6.7137\n",
      "Epoch 1155/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6661 - val_loss: 6.6920\n",
      "Epoch 1156/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6447 - val_loss: 6.5992\n",
      "Epoch 1157/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9686 - val_loss: 6.8133\n",
      "Epoch 1158/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6734 - val_loss: 6.6011\n",
      "Epoch 1159/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5591 - val_loss: 6.8458\n",
      "Epoch 1160/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4702 - val_loss: 6.5037\n",
      "Epoch 1161/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8404 - val_loss: 6.4908\n",
      "Epoch 1162/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9944 - val_loss: 6.4834\n",
      "Epoch 1163/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5608 - val_loss: 6.4305\n",
      "Epoch 1164/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9447 - val_loss: 6.6165\n",
      "Epoch 1165/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5387 - val_loss: 6.6494\n",
      "Epoch 1166/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4496 - val_loss: 6.6918\n",
      "Epoch 1167/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9635 - val_loss: 8.0665\n",
      "Epoch 1168/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9976 - val_loss: 6.6640\n",
      "Epoch 1169/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7237 - val_loss: 6.5662\n",
      "Epoch 1170/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8746 - val_loss: 6.4907\n",
      "Epoch 1171/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6671 - val_loss: 7.8510\n",
      "Epoch 1172/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5642 - val_loss: 7.0638\n",
      "Epoch 1173/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6321 - val_loss: 6.6459\n",
      "Epoch 1174/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6974 - val_loss: 7.6193\n",
      "Epoch 1175/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6488 - val_loss: 6.5383\n",
      "Epoch 1176/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9164 - val_loss: 7.0158\n",
      "Epoch 1177/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3384 - val_loss: 7.6423\n",
      "Epoch 1178/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6984 - val_loss: 6.7025\n",
      "Epoch 1179/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8002 - val_loss: 6.7903\n",
      "Epoch 1180/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6618 - val_loss: 7.3329\n",
      "Epoch 1181/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8718 - val_loss: 7.0417\n",
      "Epoch 1182/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9960 - val_loss: 6.6543\n",
      "Epoch 1183/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3521 - val_loss: 8.5120\n",
      "Epoch 1184/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7862 - val_loss: 6.6223\n",
      "Epoch 1185/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6853 - val_loss: 7.5969\n",
      "Epoch 1186/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9794 - val_loss: 6.5474\n",
      "Epoch 1187/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9578 - val_loss: 6.7281\n",
      "Epoch 1188/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7935 - val_loss: 8.3801\n",
      "Epoch 1189/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2483 - val_loss: 7.0335\n",
      "Epoch 1190/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4461 - val_loss: 6.5445\n",
      "Epoch 1191/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4645 - val_loss: 6.6154\n",
      "Epoch 1192/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9513 - val_loss: 7.1938\n",
      "Epoch 1193/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0376 - val_loss: 6.7972\n",
      "Epoch 1194/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5044 - val_loss: 6.8395\n",
      "Epoch 1195/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3584 - val_loss: 6.9079\n",
      "Epoch 1196/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5129 - val_loss: 7.9152\n",
      "Epoch 1197/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7897 - val_loss: 7.5281\n",
      "Epoch 1198/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6917 - val_loss: 6.8369\n",
      "Epoch 1199/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9881 - val_loss: 7.2565\n",
      "Epoch 1200/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7320 - val_loss: 7.6733\n",
      "Epoch 1201/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5652 - val_loss: 6.6643\n",
      "Epoch 1202/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8740 - val_loss: 7.5995\n",
      "Epoch 1203/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2154 - val_loss: 6.4763\n",
      "Epoch 1204/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0185 - val_loss: 6.6987\n",
      "Epoch 1205/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6202 - val_loss: 6.7155\n",
      "Epoch 1206/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9482 - val_loss: 6.4967\n",
      "Epoch 1207/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4282 - val_loss: 6.5687\n",
      "Epoch 1208/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4157 - val_loss: 7.0885\n",
      "Epoch 1209/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7901 - val_loss: 6.8789\n",
      "Epoch 1210/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3766 - val_loss: 7.2952\n",
      "Epoch 1211/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8590 - val_loss: 8.6485\n",
      "Epoch 1212/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5390 - val_loss: 6.6659\n",
      "Epoch 1213/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8009 - val_loss: 6.8851\n",
      "Epoch 1214/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6015 - val_loss: 7.1098\n",
      "Epoch 1215/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4531 - val_loss: 6.6974\n",
      "Epoch 1216/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3055 - val_loss: 6.6482\n",
      "Epoch 1217/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8111 - val_loss: 6.9183\n",
      "Epoch 1218/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1382 - val_loss: 6.5253\n",
      "Epoch 1219/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3816 - val_loss: 6.8862\n",
      "Epoch 1220/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7679 - val_loss: 6.7788\n",
      "Epoch 1221/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7408 - val_loss: 7.6926\n",
      "Epoch 1222/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5293 - val_loss: 6.7222\n",
      "Epoch 1223/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7109 - val_loss: 6.5874\n",
      "Epoch 1224/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3883 - val_loss: 7.2241\n",
      "Epoch 1225/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4312 - val_loss: 6.6060\n",
      "Epoch 1226/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4370 - val_loss: 7.1829\n",
      "Epoch 1227/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3386 - val_loss: 6.7539\n",
      "Epoch 1228/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5338 - val_loss: 7.0282\n",
      "Epoch 1229/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5541 - val_loss: 7.5516\n",
      "Epoch 1230/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7720 - val_loss: 6.6403\n",
      "Epoch 1231/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4995 - val_loss: 7.3905\n",
      "Epoch 1232/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8332 - val_loss: 7.5363\n",
      "Epoch 1233/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9193 - val_loss: 6.9074\n",
      "Epoch 1234/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6096 - val_loss: 6.9869\n",
      "Epoch 1235/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5511 - val_loss: 6.4803\n",
      "Epoch 1236/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6338 - val_loss: 6.5160\n",
      "Epoch 1237/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4375 - val_loss: 6.7614\n",
      "Epoch 1238/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4385 - val_loss: 7.9758\n",
      "Epoch 1239/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3496 - val_loss: 6.8334\n",
      "Epoch 1240/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5469 - val_loss: 6.3452\n",
      "Epoch 1241/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3743 - val_loss: 6.9450\n",
      "Epoch 1242/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9073 - val_loss: 8.4474\n",
      "Epoch 1243/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9266 - val_loss: 6.6937\n",
      "Epoch 1244/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7034 - val_loss: 7.3264\n",
      "Epoch 1245/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6388 - val_loss: 6.4434\n",
      "Epoch 1246/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3768 - val_loss: 6.6968\n",
      "Epoch 1247/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.2467 - val_loss: 7.1199\n",
      "Epoch 1248/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8286 - val_loss: 8.4771\n",
      "Epoch 1249/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7031 - val_loss: 6.7916\n",
      "Epoch 1250/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.2826 - val_loss: 6.9489\n",
      "Epoch 1251/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4860 - val_loss: 6.7843\n",
      "Epoch 1252/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4387 - val_loss: 6.8904\n",
      "Epoch 1253/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1350 - val_loss: 7.0363\n",
      "Epoch 1254/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2822 - val_loss: 6.6345\n",
      "Epoch 1255/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4746 - val_loss: 6.9159\n",
      "Epoch 1256/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8894 - val_loss: 6.4985\n",
      "Epoch 1257/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6840 - val_loss: 6.7518\n",
      "Epoch 1258/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.2352 - val_loss: 7.7073\n",
      "Epoch 1259/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6095 - val_loss: 6.8411\n",
      "Epoch 1260/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7094 - val_loss: 6.7189\n",
      "Epoch 1261/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4096 - val_loss: 7.0416\n",
      "Epoch 1262/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.6128 - val_loss: 8.4190\n",
      "Epoch 1263/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7316 - val_loss: 7.1068\n",
      "Epoch 1264/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3071 - val_loss: 6.6611\n",
      "Epoch 1265/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1766 - val_loss: 6.8063\n",
      "Epoch 1266/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4262 - val_loss: 6.8973\n",
      "Epoch 1267/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4156 - val_loss: 6.3895\n",
      "Epoch 1268/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4625 - val_loss: 6.6027\n",
      "Epoch 1269/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4950 - val_loss: 7.3440\n",
      "Epoch 1270/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4595 - val_loss: 6.8719\n",
      "Epoch 1271/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6407 - val_loss: 7.7796\n",
      "Epoch 1272/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6723 - val_loss: 7.1166\n",
      "Epoch 1273/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2820 - val_loss: 7.1653\n",
      "Epoch 1274/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6743 - 0s 3ms/step - loss: 4.4133 - val_loss: 6.7284\n",
      "Epoch 1275/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4696 - val_loss: 7.0260\n",
      "Epoch 1276/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2728 - val_loss: 6.7291\n",
      "Epoch 1277/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3019 - val_loss: 7.3309\n",
      "Epoch 1278/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3580 - val_loss: 6.8571\n",
      "Epoch 1279/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6022 - val_loss: 7.7232\n",
      "Epoch 1280/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5627 - val_loss: 6.7783\n",
      "Epoch 1281/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4107 - val_loss: 6.5613\n",
      "Epoch 1282/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4740 - val_loss: 7.1406\n",
      "Epoch 1283/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1462 - val_loss: 6.9979\n",
      "Epoch 1284/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1349 - val_loss: 7.5059\n",
      "Epoch 1285/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3170 - val_loss: 6.8582\n",
      "Epoch 1286/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3627 - val_loss: 7.0919\n",
      "Epoch 1287/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5441 - val_loss: 7.1451\n",
      "Epoch 1288/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3170 - val_loss: 7.9428\n",
      "Epoch 1289/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2974 - val_loss: 6.8447\n",
      "Epoch 1290/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1163 - val_loss: 6.7582\n",
      "Epoch 1291/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5428 - val_loss: 8.1755\n",
      "Epoch 1292/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3852 - val_loss: 6.6623\n",
      "Epoch 1293/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6572 - val_loss: 6.9724\n",
      "Epoch 1294/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1578 - val_loss: 6.8159\n",
      "Epoch 1295/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2554 - val_loss: 9.5931\n",
      "Epoch 1296/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5436 - val_loss: 6.8082\n",
      "Epoch 1297/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2540 - val_loss: 7.1993\n",
      "Epoch 1298/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6669 - val_loss: 7.2875\n",
      "Epoch 1299/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1987 - val_loss: 7.3029\n",
      "Epoch 1300/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3247 - val_loss: 7.1892\n",
      "Epoch 1301/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1820 - val_loss: 7.0162\n",
      "Epoch 1302/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1640 - val_loss: 6.5943\n",
      "Epoch 1303/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3942 - val_loss: 7.3578\n",
      "Epoch 1304/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4274 - val_loss: 7.1379\n",
      "Epoch 1305/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3828 - val_loss: 7.1673\n",
      "Epoch 1306/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1743 - val_loss: 6.8881\n",
      "Epoch 1307/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4937 - val_loss: 6.8207\n",
      "Epoch 1308/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3119 - val_loss: 7.0044\n",
      "Epoch 1309/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3236 - val_loss: 6.7853\n",
      "Epoch 1310/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8229 - val_loss: 6.9437\n",
      "Epoch 1311/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1759 - val_loss: 7.2225\n",
      "Epoch 1312/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3359 - val_loss: 7.5528\n",
      "Epoch 1313/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1388 - val_loss: 6.7005\n",
      "Epoch 1314/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2777 - val_loss: 7.5385\n",
      "Epoch 1315/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1208 - val_loss: 6.5836\n",
      "Epoch 1316/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2595 - val_loss: 7.0317\n",
      "Epoch 1317/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1197 - val_loss: 7.2796\n",
      "Epoch 1318/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3003 - val_loss: 6.8848\n",
      "Epoch 1319/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6999 - val_loss: 6.9799\n",
      "Epoch 1320/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0722 - val_loss: 6.7820\n",
      "Epoch 1321/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3715 - val_loss: 6.7294\n",
      "Epoch 1322/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9551 - val_loss: 7.9746\n",
      "Epoch 1323/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1644 - val_loss: 6.6826\n",
      "Epoch 1324/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1616 - val_loss: 7.2743\n",
      "Epoch 1325/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2517 - val_loss: 7.2621\n",
      "Epoch 1326/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3208 - val_loss: 7.3614\n",
      "Epoch 1327/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2596 - val_loss: 7.2132\n",
      "Epoch 1328/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4102 - val_loss: 6.9427\n",
      "Epoch 1329/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2928 - val_loss: 7.5476\n",
      "Epoch 1330/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4740 - val_loss: 6.9948\n",
      "Epoch 1331/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1820 - val_loss: 7.3278\n",
      "Epoch 1332/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3570 - val_loss: 6.8139\n",
      "Epoch 1333/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5710 - val_loss: 9.2083\n",
      "Epoch 1334/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3390 - val_loss: 6.9122\n",
      "Epoch 1335/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1363 - val_loss: 6.8615\n",
      "Epoch 1336/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9705 - val_loss: 7.4732\n",
      "Epoch 1337/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2827 - val_loss: 7.3855\n",
      "Epoch 1338/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2116 - val_loss: 7.0774\n",
      "Epoch 1339/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1829 - val_loss: 7.0228\n",
      "Epoch 1340/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4420 - val_loss: 7.2268\n",
      "Epoch 1341/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0599 - val_loss: 7.5142\n",
      "Epoch 1342/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3606 - val_loss: 7.3293\n",
      "Epoch 1343/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1598 - val_loss: 7.3208\n",
      "Epoch 1344/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4660 - val_loss: 7.1801\n",
      "Epoch 1345/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3408 - val_loss: 7.7341\n",
      "Epoch 1346/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3740 - val_loss: 8.1214\n",
      "Epoch 1347/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4292 - val_loss: 7.1281\n",
      "Epoch 1348/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3738 - val_loss: 9.3091\n",
      "Epoch 1349/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2328 - val_loss: 7.0659\n",
      "Epoch 1350/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2461 - val_loss: 7.2366\n",
      "Epoch 1351/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0980 - val_loss: 7.3077\n",
      "Epoch 1352/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9408 - val_loss: 7.2424\n",
      "Epoch 1353/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3813 - val_loss: 7.1176\n",
      "Epoch 1354/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0189 - val_loss: 6.9677\n",
      "Epoch 1355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2102 - val_loss: 7.4369\n",
      "Epoch 1356/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.2996 - val_loss: 7.9571\n",
      "Epoch 1357/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2520 - val_loss: 8.5974\n",
      "Epoch 1358/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3036 - val_loss: 7.0038\n",
      "Epoch 1359/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.2092 - val_loss: 7.1330\n",
      "Epoch 1360/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0022 - val_loss: 7.3255\n",
      "Epoch 1361/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0323 - val_loss: 7.4135\n",
      "Epoch 1362/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0206 - val_loss: 6.9631\n",
      "Epoch 1363/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9481 - val_loss: 6.6358\n",
      "Epoch 1364/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0775 - val_loss: 6.8823\n",
      "Epoch 1365/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7507 - val_loss: 7.1249\n",
      "Epoch 1366/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2745 - val_loss: 6.9100\n",
      "Epoch 1367/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0064 - val_loss: 8.0030\n",
      "Epoch 1368/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3633 - val_loss: 7.8342\n",
      "Epoch 1369/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1671 - val_loss: 7.6521\n",
      "Epoch 1370/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2271 - val_loss: 6.8863\n",
      "Epoch 1371/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2551 - val_loss: 6.7362\n",
      "Epoch 1372/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2082 - val_loss: 7.5809\n",
      "Epoch 1373/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6705 - val_loss: 6.8011\n",
      "Epoch 1374/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9278 - val_loss: 7.1588\n",
      "Epoch 1375/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7021 - val_loss: 7.2953\n",
      "Epoch 1376/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0660 - val_loss: 7.1075\n",
      "Epoch 1377/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2823 - val_loss: 8.0892\n",
      "Epoch 1378/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1584 - val_loss: 6.9334\n",
      "Epoch 1379/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1410 - val_loss: 7.6643\n",
      "Epoch 1380/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9575 - val_loss: 7.1834\n",
      "Epoch 1381/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0645 - val_loss: 7.2328\n",
      "Epoch 1382/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1453 - val_loss: 7.3836\n",
      "Epoch 1383/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9517 - val_loss: 6.8073\n",
      "Epoch 1384/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9593 - val_loss: 8.1635\n",
      "Epoch 1385/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4622 - val_loss: 8.0001\n",
      "Epoch 1386/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4109 - val_loss: 7.4293\n",
      "Epoch 1387/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0564 - val_loss: 6.9239\n",
      "Epoch 1388/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1760 - val_loss: 7.3592\n",
      "Epoch 1389/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7052 - val_loss: 7.2774\n",
      "Epoch 1390/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1977 - val_loss: 9.1216\n",
      "Epoch 1391/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1370 - val_loss: 6.7783\n",
      "Epoch 1392/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1010 - val_loss: 7.8606\n",
      "Epoch 1393/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9907 - val_loss: 7.2432\n",
      "Epoch 1394/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7650 - val_loss: 7.1065\n",
      "Epoch 1395/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2220 - val_loss: 8.6396\n",
      "Epoch 1396/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3599 - val_loss: 6.7794\n",
      "Epoch 1397/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2259 - val_loss: 8.8564\n",
      "Epoch 1398/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1433 - val_loss: 7.4071\n",
      "Epoch 1399/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0983 - val_loss: 7.2472\n",
      "Epoch 1400/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0073 - val_loss: 8.3428\n",
      "Epoch 1401/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1217 - val_loss: 7.3696\n",
      "Epoch 1402/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9820 - val_loss: 7.3449\n",
      "Epoch 1403/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8145 - val_loss: 7.0807\n",
      "Epoch 1404/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0298 - val_loss: 8.5870\n",
      "Epoch 1405/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6575 - val_loss: 7.5050\n",
      "Epoch 1406/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1190 - val_loss: 8.0533\n",
      "Epoch 1407/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2294 - val_loss: 8.9230\n",
      "Epoch 1408/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6301 - val_loss: 7.1880\n",
      "Epoch 1409/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9933 - val_loss: 10.3850\n",
      "Epoch 1410/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4803 - val_loss: 7.0545\n",
      "Epoch 1411/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1618 - val_loss: 7.7731\n",
      "Epoch 1412/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8736 - val_loss: 6.9532\n",
      "Epoch 1413/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0935 - val_loss: 8.7514\n",
      "Epoch 1414/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7041 - val_loss: 6.9773\n",
      "Epoch 1415/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1039 - val_loss: 8.0322\n",
      "Epoch 1416/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9364 - val_loss: 6.8666\n",
      "Epoch 1417/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9901 - val_loss: 7.3046\n",
      "Epoch 1418/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0448 - val_loss: 7.0629\n",
      "Epoch 1419/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3143 - val_loss: 7.2599\n",
      "Epoch 1420/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9079 - val_loss: 7.2132\n",
      "Epoch 1421/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7883 - val_loss: 7.3224\n",
      "Epoch 1422/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9432 - val_loss: 6.9622\n",
      "Epoch 1423/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6157 - val_loss: 8.3603\n",
      "Epoch 1424/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3950 - val_loss: 7.5548\n",
      "Epoch 1425/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1398 - val_loss: 6.8624\n",
      "Epoch 1426/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8074 - val_loss: 7.6479\n",
      "Epoch 1427/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8998 - val_loss: 6.8653\n",
      "Epoch 1428/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4195 - val_loss: 7.4672\n",
      "Epoch 1429/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0191 - val_loss: 7.3178\n",
      "Epoch 1430/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8740 - val_loss: 7.3364\n",
      "Epoch 1431/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0469 - val_loss: 7.3319\n",
      "Epoch 1432/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0125 - val_loss: 7.3084\n",
      "Epoch 1433/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8306 - val_loss: 7.1018\n",
      "Epoch 1434/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7853 - val_loss: 8.3980\n",
      "Epoch 1435/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3442 - val_loss: 7.0839\n",
      "Epoch 1436/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8884 - val_loss: 7.7420\n",
      "Epoch 1437/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9959 - val_loss: 7.6739\n",
      "Epoch 1438/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7306 - val_loss: 7.4938\n",
      "Epoch 1439/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2766 - val_loss: 7.9466\n",
      "Epoch 1440/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2100 - val_loss: 7.3834\n",
      "Epoch 1441/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0934 - val_loss: 7.0471\n",
      "Epoch 1442/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9065 - val_loss: 6.9783\n",
      "Epoch 1443/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0714 - val_loss: 7.2637\n",
      "Epoch 1444/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9038 - val_loss: 7.7907\n",
      "Epoch 1445/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7869 - val_loss: 7.0764\n",
      "Epoch 1446/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1450 - val_loss: 9.0829\n",
      "Epoch 1447/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8720 - val_loss: 6.8506\n",
      "Epoch 1448/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7996 - val_loss: 7.3781\n",
      "Epoch 1449/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1551 - val_loss: 7.5830\n",
      "Epoch 1450/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2417 - val_loss: 7.6933\n",
      "Epoch 1451/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9802 - val_loss: 7.9964\n",
      "Epoch 1452/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9467 - val_loss: 7.5488\n",
      "Epoch 1453/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8345 - val_loss: 8.1060\n",
      "Epoch 1454/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3648 - val_loss: 7.9548\n",
      "Epoch 1455/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0571 - val_loss: 7.6995\n",
      "Epoch 1456/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1098 - val_loss: 7.3233\n",
      "Epoch 1457/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0278 - val_loss: 8.7000\n",
      "Epoch 1458/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1525 - val_loss: 6.9842\n",
      "Epoch 1459/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0796 - val_loss: 8.0536\n",
      "Epoch 1460/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8496 - val_loss: 7.8521\n",
      "Epoch 1461/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1516 - val_loss: 7.1946\n",
      "Epoch 1462/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8397 - val_loss: 8.6975\n",
      "Epoch 1463/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9177 - val_loss: 7.3271\n",
      "Epoch 1464/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8577 - val_loss: 7.4887\n",
      "Epoch 1465/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1348 - val_loss: 7.0571\n",
      "Epoch 1466/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0650 - val_loss: 7.5680\n",
      "Epoch 1467/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7944 - val_loss: 8.6639\n",
      "Epoch 1468/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0345 - val_loss: 6.9562\n",
      "Epoch 1469/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8882 - val_loss: 7.5339\n",
      "Epoch 1470/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9738 - val_loss: 7.3317\n",
      "Epoch 1471/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1649 - val_loss: 8.2684\n",
      "Epoch 1472/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.2418 - val_loss: 8.1934\n",
      "Epoch 1473/2000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.7669 - val_loss: 7.2866\n",
      "Epoch 1474/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7582 - val_loss: 7.5075\n",
      "Epoch 1475/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0059 - val_loss: 7.0215\n",
      "Epoch 1476/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1309 - val_loss: 7.4822\n",
      "Epoch 1477/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7661 - val_loss: 7.3615\n",
      "Epoch 1478/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.2089 - val_loss: 7.8070\n",
      "Epoch 1479/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9342 - val_loss: 7.0956\n",
      "Epoch 1480/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0582 - val_loss: 7.4061\n",
      "Epoch 1481/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9577 - val_loss: 8.0029\n",
      "Epoch 1482/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9230 - val_loss: 6.8586\n",
      "Epoch 1483/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8564 - val_loss: 7.2504\n",
      "Epoch 1484/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7856 - val_loss: 8.6760\n",
      "Epoch 1485/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7867 - val_loss: 6.9947\n",
      "Epoch 1486/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9563 - val_loss: 7.5402\n",
      "Epoch 1487/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1409 - val_loss: 8.4712\n",
      "Epoch 1488/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0156 - val_loss: 7.8350\n",
      "Epoch 1489/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7095 - val_loss: 7.8205\n",
      "Epoch 1490/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9809 - val_loss: 7.4069\n",
      "Epoch 1491/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7754 - val_loss: 7.2241\n",
      "Epoch 1492/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8582 - val_loss: 7.9332\n",
      "Epoch 1493/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1693 - val_loss: 7.5555\n",
      "Epoch 1494/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0763 - val_loss: 7.4650\n",
      "Epoch 1495/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3447 - val_loss: 8.5253\n",
      "Epoch 1496/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8450 - val_loss: 7.7495\n",
      "Epoch 1497/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1450 - val_loss: 7.8919\n",
      "Epoch 1498/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9381 - val_loss: 8.8191\n",
      "Epoch 1499/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8447 - val_loss: 8.2011\n",
      "Epoch 1500/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2018 - val_loss: 8.3277\n",
      "Epoch 1501/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3808 - val_loss: 7.1887\n",
      "Epoch 1502/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9327 - val_loss: 7.8236\n",
      "Epoch 1503/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1489 - val_loss: 7.2999\n",
      "Epoch 1504/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6452 - val_loss: 7.2626\n",
      "Epoch 1505/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9746 - val_loss: 7.1169\n",
      "Epoch 1506/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9275 - val_loss: 7.2655\n",
      "Epoch 1507/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9302 - val_loss: 7.1043\n",
      "Epoch 1508/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8987 - val_loss: 8.1733\n",
      "Epoch 1509/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9650 - val_loss: 8.4874\n",
      "Epoch 1510/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9094 - val_loss: 7.5660\n",
      "Epoch 1511/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9510 - val_loss: 7.2522\n",
      "Epoch 1512/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7113 - val_loss: 7.4116\n",
      "Epoch 1513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1065 - val_loss: 7.9461\n",
      "Epoch 1514/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9517 - val_loss: 7.1533\n",
      "Epoch 1515/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8562 - val_loss: 7.1837\n",
      "Epoch 1516/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8011 - val_loss: 8.0184\n",
      "Epoch 1517/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9598 - val_loss: 7.6413\n",
      "Epoch 1518/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8367 - val_loss: 6.9779\n",
      "Epoch 1519/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8522 - val_loss: 8.1651\n",
      "Epoch 1520/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9759 - val_loss: 8.2024\n",
      "Epoch 1521/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0908 - val_loss: 7.7952\n",
      "Epoch 1522/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8939 - val_loss: 7.9995\n",
      "Epoch 1523/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7623 - val_loss: 7.3552\n",
      "Epoch 1524/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6172 - val_loss: 7.3261\n",
      "Epoch 1525/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8495 - val_loss: 7.3938\n",
      "Epoch 1526/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9491 - val_loss: 7.7362\n",
      "Epoch 1527/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8452 - val_loss: 8.6094\n",
      "Epoch 1528/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9999 - val_loss: 7.3794\n",
      "Epoch 1529/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9967 - val_loss: 7.3148\n",
      "Epoch 1530/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7654 - val_loss: 8.0719\n",
      "Epoch 1531/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1170 - val_loss: 7.2109\n",
      "Epoch 1532/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7118 - val_loss: 7.8761\n",
      "Epoch 1533/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7638 - val_loss: 6.9771\n",
      "Epoch 1534/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5472 - val_loss: 7.2054\n",
      "Epoch 1535/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6242 - val_loss: 7.5930\n",
      "Epoch 1536/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7574 - val_loss: 7.7346\n",
      "Epoch 1537/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9211 - val_loss: 9.6218\n",
      "Epoch 1538/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0464 - val_loss: 7.1799\n",
      "Epoch 1539/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6496 - val_loss: 7.9782\n",
      "Epoch 1540/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6453 - val_loss: 7.4042\n",
      "Epoch 1541/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0282 - val_loss: 7.2335\n",
      "Epoch 1542/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7752 - val_loss: 7.2676\n",
      "Epoch 1543/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7206 - val_loss: 7.0046\n",
      "Epoch 1544/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7988 - val_loss: 7.1261\n",
      "Epoch 1545/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7708 - val_loss: 7.6226\n",
      "Epoch 1546/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5659 - val_loss: 7.9198\n",
      "Epoch 1547/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4319 - val_loss: 8.2754\n",
      "Epoch 1548/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8787 - val_loss: 7.6680\n",
      "Epoch 1549/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7988 - val_loss: 7.7438\n",
      "Epoch 1550/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7125 - val_loss: 7.7692\n",
      "Epoch 1551/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0811 - val_loss: 7.3051\n",
      "Epoch 1552/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8378 - val_loss: 7.3681\n",
      "Epoch 1553/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7860 - val_loss: 7.6410\n",
      "Epoch 1554/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6702 - val_loss: 7.5970\n",
      "Epoch 1555/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8798 - val_loss: 7.7564\n",
      "Epoch 1556/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1815 - val_loss: 8.0511\n",
      "Epoch 1557/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0400 - val_loss: 8.3557\n",
      "Epoch 1558/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8249 - val_loss: 7.6463\n",
      "Epoch 1559/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6088 - val_loss: 7.4780\n",
      "Epoch 1560/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7368 - val_loss: 9.4213\n",
      "Epoch 1561/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8907 - val_loss: 7.2949\n",
      "Epoch 1562/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6738 - val_loss: 8.4497\n",
      "Epoch 1563/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1313 - val_loss: 7.7378\n",
      "Epoch 1564/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2649 - val_loss: 7.9096\n",
      "Epoch 1565/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1149 - val_loss: 8.1213\n",
      "Epoch 1566/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8103 - val_loss: 8.4668\n",
      "Epoch 1567/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1807 - val_loss: 8.0477\n",
      "Epoch 1568/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8406 - val_loss: 7.4660\n",
      "Epoch 1569/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6765 - val_loss: 8.9786\n",
      "Epoch 1570/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0900 - val_loss: 7.0170\n",
      "Epoch 1571/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7470 - val_loss: 8.2615\n",
      "Epoch 1572/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9948 - val_loss: 7.5567\n",
      "Epoch 1573/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7307 - val_loss: 7.8115\n",
      "Epoch 1574/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9569 - val_loss: 8.3908\n",
      "Epoch 1575/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8428 - val_loss: 7.6616\n",
      "Epoch 1576/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7409 - val_loss: 8.4258\n",
      "Epoch 1577/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6560 - val_loss: 7.5375\n",
      "Epoch 1578/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6803 - val_loss: 8.1705\n",
      "Epoch 1579/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6738 - val_loss: 7.6400\n",
      "Epoch 1580/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7183 - val_loss: 7.8194\n",
      "Epoch 1581/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8187 - val_loss: 7.1152\n",
      "Epoch 1582/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9332 - val_loss: 7.1817\n",
      "Epoch 1583/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9736 - val_loss: 8.3566\n",
      "Epoch 1584/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0025 - val_loss: 8.2545\n",
      "Epoch 1585/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6252 - val_loss: 7.7163\n",
      "Epoch 1586/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6948 - val_loss: 7.3492\n",
      "Epoch 1587/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6474 - val_loss: 8.0841\n",
      "Epoch 1588/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1234 - val_loss: 7.3083\n",
      "Epoch 1589/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6121 - val_loss: 8.6270\n",
      "Epoch 1590/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2139 - val_loss: 7.9229\n",
      "Epoch 1591/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8526 - val_loss: 7.2658\n",
      "Epoch 1592/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0426 - val_loss: 7.6622\n",
      "Epoch 1593/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2387 - val_loss: 8.4473\n",
      "Epoch 1594/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5387 - val_loss: 7.0058\n",
      "Epoch 1595/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0915 - val_loss: 7.2752\n",
      "Epoch 1596/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8012 - val_loss: 7.4089\n",
      "Epoch 1597/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0279 - val_loss: 8.6543\n",
      "Epoch 1598/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5229 - val_loss: 7.0248\n",
      "Epoch 1599/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6648 - val_loss: 7.9775\n",
      "Epoch 1600/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6420 - val_loss: 7.4896\n",
      "Epoch 1601/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5366 - val_loss: 7.6379\n",
      "Epoch 1602/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6229 - val_loss: 7.5192\n",
      "Epoch 1603/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5008 - val_loss: 7.2986\n",
      "Epoch 1604/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6930 - val_loss: 8.2896\n",
      "Epoch 1605/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5944 - val_loss: 7.4432\n",
      "Epoch 1606/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5617 - val_loss: 7.5194\n",
      "Epoch 1607/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8891 - val_loss: 7.4363\n",
      "Epoch 1608/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8165 - val_loss: 7.5257\n",
      "Epoch 1609/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6988 - val_loss: 7.4380\n",
      "Epoch 1610/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8276 - val_loss: 8.1456\n",
      "Epoch 1611/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9491 - val_loss: 6.9552\n",
      "Epoch 1612/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0628 - val_loss: 8.3026\n",
      "Epoch 1613/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6792 - val_loss: 7.3638\n",
      "Epoch 1614/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3994 - val_loss: 7.9368\n",
      "Epoch 1615/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7964 - val_loss: 7.4455\n",
      "Epoch 1616/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4614 - val_loss: 8.4855\n",
      "Epoch 1617/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8008 - val_loss: 7.1583\n",
      "Epoch 1618/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7024 - val_loss: 7.5012\n",
      "Epoch 1619/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5669 - val_loss: 8.1437\n",
      "Epoch 1620/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6200 - val_loss: 7.6865\n",
      "Epoch 1621/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7929 - val_loss: 7.8887\n",
      "Epoch 1622/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6587 - val_loss: 7.3920\n",
      "Epoch 1623/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8332 - val_loss: 7.4302\n",
      "Epoch 1624/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6119 - val_loss: 7.8320\n",
      "Epoch 1625/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9895 - val_loss: 7.3875\n",
      "Epoch 1626/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5966 - val_loss: 7.3087\n",
      "Epoch 1627/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5185 - val_loss: 7.7183\n",
      "Epoch 1628/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6099 - val_loss: 7.9657\n",
      "Epoch 1629/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5427 - val_loss: 7.7223\n",
      "Epoch 1630/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7726 - val_loss: 7.3915\n",
      "Epoch 1631/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9610 - val_loss: 7.5814\n",
      "Epoch 1632/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7053 - val_loss: 8.1900\n",
      "Epoch 1633/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5840 - val_loss: 7.5047\n",
      "Epoch 1634/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7526 - val_loss: 7.2603\n",
      "Epoch 1635/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7429 - val_loss: 8.0633\n",
      "Epoch 1636/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9000 - val_loss: 7.3030\n",
      "Epoch 1637/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9626 - val_loss: 8.3270\n",
      "Epoch 1638/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7734 - val_loss: 7.4656\n",
      "Epoch 1639/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5184 - val_loss: 7.2899\n",
      "Epoch 1640/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0015 - val_loss: 7.7862\n",
      "Epoch 1641/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7047 - val_loss: 8.3975\n",
      "Epoch 1642/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5967 - val_loss: 8.3220\n",
      "Epoch 1643/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7262 - val_loss: 7.4950\n",
      "Epoch 1644/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4945 - val_loss: 7.1622\n",
      "Epoch 1645/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9391 - val_loss: 7.8695\n",
      "Epoch 1646/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7438 - val_loss: 8.1304\n",
      "Epoch 1647/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7885 - val_loss: 7.5506\n",
      "Epoch 1648/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9415 - val_loss: 8.1665\n",
      "Epoch 1649/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6755 - val_loss: 7.7411\n",
      "Epoch 1650/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6537 - val_loss: 7.4679\n",
      "Epoch 1651/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.460 - 0s 4ms/step - loss: 3.6723 - val_loss: 7.7019\n",
      "Epoch 1652/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6604 - val_loss: 7.5327\n",
      "Epoch 1653/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7176 - val_loss: 7.6975\n",
      "Epoch 1654/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8084 - val_loss: 7.4328\n",
      "Epoch 1655/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7430 - val_loss: 8.6018\n",
      "Epoch 1656/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1595 - val_loss: 7.6056\n",
      "Epoch 1657/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.111 - 0s 4ms/step - loss: 3.6166 - val_loss: 7.2898\n",
      "Epoch 1658/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7430 - val_loss: 7.5842\n",
      "Epoch 1659/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7506 - val_loss: 7.5240\n",
      "Epoch 1660/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7770 - val_loss: 7.7784\n",
      "Epoch 1661/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7346 - val_loss: 7.4762\n",
      "Epoch 1662/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7289 - val_loss: 7.8557\n",
      "Epoch 1663/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7964 - val_loss: 8.1977\n",
      "Epoch 1664/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1477 - val_loss: 7.1737\n",
      "Epoch 1665/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8307 - val_loss: 7.7509\n",
      "Epoch 1666/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6310 - val_loss: 6.8387\n",
      "Epoch 1667/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8333 - val_loss: 7.6490\n",
      "Epoch 1668/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6095 - val_loss: 8.1468\n",
      "Epoch 1669/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3500 - val_loss: 7.8236\n",
      "Epoch 1670/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4692 - val_loss: 7.0872\n",
      "Epoch 1671/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6808 - val_loss: 7.8207\n",
      "Epoch 1672/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5328 - val_loss: 7.7242\n",
      "Epoch 1673/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4792 - val_loss: 7.4212\n",
      "Epoch 1674/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5618 - val_loss: 7.5555\n",
      "Epoch 1675/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4583 - val_loss: 8.4076\n",
      "Epoch 1676/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6330 - val_loss: 7.8264\n",
      "Epoch 1677/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6978 - val_loss: 7.3184\n",
      "Epoch 1678/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8381 - val_loss: 7.6863\n",
      "Epoch 1679/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9018 - val_loss: 10.0333\n",
      "Epoch 1680/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2666 - val_loss: 7.4523\n",
      "Epoch 1681/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0570 - val_loss: 8.6305\n",
      "Epoch 1682/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6977 - val_loss: 7.2481\n",
      "Epoch 1683/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5660 - val_loss: 8.9882\n",
      "Epoch 1684/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6234 - val_loss: 7.9913\n",
      "Epoch 1685/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5340 - val_loss: 7.2317\n",
      "Epoch 1686/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4463 - val_loss: 8.3988\n",
      "Epoch 1687/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3653 - val_loss: 7.6893\n",
      "Epoch 1688/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6920 - val_loss: 8.7389\n",
      "Epoch 1689/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5649 - val_loss: 7.5648\n",
      "Epoch 1690/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4528 - val_loss: 7.6548\n",
      "Epoch 1691/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7808 - val_loss: 7.5289\n",
      "Epoch 1692/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5233 - val_loss: 8.4816\n",
      "Epoch 1693/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4062 - val_loss: 7.8638\n",
      "Epoch 1694/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5614 - val_loss: 8.2331\n",
      "Epoch 1695/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7383 - val_loss: 7.5748\n",
      "Epoch 1696/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7977 - val_loss: 8.9203\n",
      "Epoch 1697/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2749 - val_loss: 7.7803\n",
      "Epoch 1698/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8501 - val_loss: 7.1947\n",
      "Epoch 1699/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7244 - val_loss: 7.6083\n",
      "Epoch 1700/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7777 - val_loss: 7.3096\n",
      "Epoch 1701/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4703 - val_loss: 8.7494\n",
      "Epoch 1702/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5395 - val_loss: 7.3281\n",
      "Epoch 1703/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8513 - val_loss: 8.2857\n",
      "Epoch 1704/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4318 - val_loss: 7.6444\n",
      "Epoch 1705/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4315 - val_loss: 7.9831\n",
      "Epoch 1706/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6623 - val_loss: 7.9517\n",
      "Epoch 1707/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9430 - val_loss: 7.7023\n",
      "Epoch 1708/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8849 - val_loss: 8.1143\n",
      "Epoch 1709/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2555 - val_loss: 10.0340\n",
      "Epoch 1710/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7761 - val_loss: 7.9564\n",
      "Epoch 1711/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6562 - val_loss: 8.0584\n",
      "Epoch 1712/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3795 - val_loss: 7.8869\n",
      "Epoch 1713/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4694 - val_loss: 8.1506\n",
      "Epoch 1714/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1928 - val_loss: 8.2042\n",
      "Epoch 1715/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6542 - val_loss: 7.7174\n",
      "Epoch 1716/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6918 - val_loss: 8.1840\n",
      "Epoch 1717/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5858 - val_loss: 7.5357\n",
      "Epoch 1718/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4689 - val_loss: 7.3690\n",
      "Epoch 1719/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6425 - val_loss: 7.3441\n",
      "Epoch 1720/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8539 - val_loss: 10.9546\n",
      "Epoch 1721/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7543 - val_loss: 7.9994\n",
      "Epoch 1722/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4347 - val_loss: 7.6015\n",
      "Epoch 1723/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4708 - val_loss: 8.9601\n",
      "Epoch 1724/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9478 - val_loss: 8.1050\n",
      "Epoch 1725/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5842 - val_loss: 8.0861\n",
      "Epoch 1726/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4694 - val_loss: 8.1559\n",
      "Epoch 1727/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5635 - val_loss: 8.1686\n",
      "Epoch 1728/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3489 - val_loss: 7.8409\n",
      "Epoch 1729/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4474 - val_loss: 7.5729\n",
      "Epoch 1730/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7382 - val_loss: 7.8378\n",
      "Epoch 1731/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6085 - val_loss: 7.4557\n",
      "Epoch 1732/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4129 - val_loss: 8.2714\n",
      "Epoch 1733/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4428 - val_loss: 7.8271\n",
      "Epoch 1734/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3780 - val_loss: 7.7575\n",
      "Epoch 1735/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6225 - val_loss: 7.7789\n",
      "Epoch 1736/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6227 - val_loss: 9.4981\n",
      "Epoch 1737/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9131 - val_loss: 7.2308\n",
      "Epoch 1738/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7787 - val_loss: 7.9600\n",
      "Epoch 1739/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4585 - val_loss: 7.5355\n",
      "Epoch 1740/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6802 - val_loss: 8.2677\n",
      "Epoch 1741/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4252 - val_loss: 7.5625\n",
      "Epoch 1742/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3354 - val_loss: 8.4006\n",
      "Epoch 1743/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6805 - val_loss: 7.6207\n",
      "Epoch 1744/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7546 - val_loss: 7.4777\n",
      "Epoch 1745/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6743 - val_loss: 11.2722\n",
      "Epoch 1746/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9817 - val_loss: 7.8014\n",
      "Epoch 1747/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5223 - val_loss: 8.3733\n",
      "Epoch 1748/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5846 - val_loss: 8.0369\n",
      "Epoch 1749/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7331 - val_loss: 8.1650\n",
      "Epoch 1750/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8468 - val_loss: 9.0938\n",
      "Epoch 1751/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4840 - val_loss: 8.0956\n",
      "Epoch 1752/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4495 - val_loss: 7.8518\n",
      "Epoch 1753/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4224 - val_loss: 7.8250\n",
      "Epoch 1754/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7175 - val_loss: 8.2782\n",
      "Epoch 1755/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4783 - val_loss: 8.1410\n",
      "Epoch 1756/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3611 - val_loss: 8.8095\n",
      "Epoch 1757/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5404 - val_loss: 7.5186\n",
      "Epoch 1758/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5661 - val_loss: 8.1571\n",
      "Epoch 1759/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6382 - val_loss: 9.1577\n",
      "Epoch 1760/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5150 - val_loss: 8.1466\n",
      "Epoch 1761/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0940 - val_loss: 9.0373\n",
      "Epoch 1762/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9976 - val_loss: 7.8728\n",
      "Epoch 1763/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6546 - val_loss: 10.4014\n",
      "Epoch 1764/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3023 - val_loss: 8.5332\n",
      "Epoch 1765/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5207 - val_loss: 7.6921\n",
      "Epoch 1766/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7799 - val_loss: 8.0519\n",
      "Epoch 1767/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6611 - val_loss: 7.6541\n",
      "Epoch 1768/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0682 - val_loss: 8.4195\n",
      "Epoch 1769/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5900 - val_loss: 8.4115\n",
      "Epoch 1770/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4257 - val_loss: 7.6673\n",
      "Epoch 1771/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9315 - val_loss: 8.5815\n",
      "Epoch 1772/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6893 - val_loss: 7.7589\n",
      "Epoch 1773/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7747 - val_loss: 8.2503\n",
      "Epoch 1774/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7454 - val_loss: 8.2274\n",
      "Epoch 1775/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7391 - val_loss: 7.4296\n",
      "Epoch 1776/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8363 - val_loss: 10.1379\n",
      "Epoch 1777/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4678 - val_loss: 8.3167\n",
      "Epoch 1778/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4477 - val_loss: 7.6516\n",
      "Epoch 1779/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6748 - val_loss: 7.9034\n",
      "Epoch 1780/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6418 - val_loss: 8.0813\n",
      "Epoch 1781/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7069 - val_loss: 10.2245\n",
      "Epoch 1782/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5462 - val_loss: 8.1854\n",
      "Epoch 1783/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3959 - val_loss: 8.9641\n",
      "Epoch 1784/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4757 - val_loss: 8.4385\n",
      "Epoch 1785/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3726 - val_loss: 8.2225\n",
      "Epoch 1786/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5534 - val_loss: 8.2714\n",
      "Epoch 1787/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9470 - val_loss: 8.4384\n",
      "Epoch 1788/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6722 - val_loss: 10.0663\n",
      "Epoch 1789/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7372 - val_loss: 8.2585\n",
      "Epoch 1790/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4869 - val_loss: 9.0913\n",
      "Epoch 1791/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3710 - val_loss: 7.5660\n",
      "Epoch 1792/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8662 - val_loss: 8.7377\n",
      "Epoch 1793/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5140 - val_loss: 7.4772\n",
      "Epoch 1794/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3439 - val_loss: 7.6317\n",
      "Epoch 1795/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3162 - val_loss: 8.9558\n",
      "Epoch 1796/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5495 - val_loss: 8.2545\n",
      "Epoch 1797/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4930 - val_loss: 7.4307\n",
      "Epoch 1798/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4926 - val_loss: 8.0660\n",
      "Epoch 1799/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5590 - val_loss: 8.0563\n",
      "Epoch 1800/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4460 - val_loss: 7.7981\n",
      "Epoch 1801/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3566 - val_loss: 7.8204\n",
      "Epoch 1802/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4831 - val_loss: 9.5150\n",
      "Epoch 1803/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9632 - val_loss: 8.5740\n",
      "Epoch 1804/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3969 - val_loss: 8.0510\n",
      "Epoch 1805/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6691 - val_loss: 7.9749\n",
      "Epoch 1806/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5122 - val_loss: 8.7618\n",
      "Epoch 1807/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7826 - val_loss: 8.5629\n",
      "Epoch 1808/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4099 - val_loss: 9.0802\n",
      "Epoch 1809/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4353 - val_loss: 8.4636\n",
      "Epoch 1810/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4192 - val_loss: 8.0531\n",
      "Epoch 1811/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3548 - val_loss: 8.0077\n",
      "Epoch 1812/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6420 - val_loss: 7.7461\n",
      "Epoch 1813/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9676 - val_loss: 7.4549\n",
      "Epoch 1814/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8411 - val_loss: 9.5850\n",
      "Epoch 1815/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5280 - val_loss: 7.7913\n",
      "Epoch 1816/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2235 - val_loss: 7.6153\n",
      "Epoch 1817/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7722 - val_loss: 10.3303\n",
      "Epoch 1818/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6923 - val_loss: 7.7055\n",
      "Epoch 1819/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.608 - 0s 4ms/step - loss: 3.4767 - val_loss: 7.9739\n",
      "Epoch 1820/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5380 - val_loss: 9.0969\n",
      "Epoch 1821/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4992 - val_loss: 8.7708\n",
      "Epoch 1822/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4056 - val_loss: 8.0705\n",
      "Epoch 1823/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3600 - val_loss: 8.0855\n",
      "Epoch 1824/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6223 - val_loss: 7.6847\n",
      "Epoch 1825/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2847 - val_loss: 9.9219\n",
      "Epoch 1826/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3411 - val_loss: 8.5790\n",
      "Epoch 1827/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4963 - val_loss: 8.5955\n",
      "Epoch 1828/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5597 - val_loss: 8.1471\n",
      "Epoch 1829/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2966 - val_loss: 8.1348\n",
      "Epoch 1830/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3722 - val_loss: 8.1144\n",
      "Epoch 1831/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9443 - val_loss: 11.3077\n",
      "Epoch 1832/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6933 - val_loss: 8.2558\n",
      "Epoch 1833/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7310 - val_loss: 8.9360\n",
      "Epoch 1834/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2657 - val_loss: 8.3609\n",
      "Epoch 1835/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3975 - val_loss: 8.1545\n",
      "Epoch 1836/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2292 - val_loss: 8.0829\n",
      "Epoch 1837/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3072 - val_loss: 8.7613\n",
      "Epoch 1838/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4388 - val_loss: 9.1195\n",
      "Epoch 1839/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7089 - val_loss: 7.9439\n",
      "Epoch 1840/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4929 - val_loss: 8.4805\n",
      "Epoch 1841/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4170 - val_loss: 8.6294\n",
      "Epoch 1842/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4685 - val_loss: 8.9289\n",
      "Epoch 1843/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7780 - val_loss: 7.9499\n",
      "Epoch 1844/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4309 - val_loss: 8.6635\n",
      "Epoch 1845/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5538 - val_loss: 7.7696\n",
      "Epoch 1846/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5191 - val_loss: 8.7875\n",
      "Epoch 1847/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6202 - val_loss: 8.0392\n",
      "Epoch 1848/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4514 - val_loss: 8.7475\n",
      "Epoch 1849/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4324 - val_loss: 7.7234\n",
      "Epoch 1850/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.2895 - val_loss: 9.8565\n",
      "Epoch 1851/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3413 - val_loss: 8.5521\n",
      "Epoch 1852/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4151 - val_loss: 8.1159\n",
      "Epoch 1853/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6125 - val_loss: 8.0790\n",
      "Epoch 1854/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5649 - val_loss: 8.9056\n",
      "Epoch 1855/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.2823 - val_loss: 8.4015\n",
      "Epoch 1856/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3642 - val_loss: 7.9185\n",
      "Epoch 1857/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4549 - val_loss: 8.8748\n",
      "Epoch 1858/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5137 - val_loss: 8.1490\n",
      "Epoch 1859/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7913 - val_loss: 10.1158\n",
      "Epoch 1860/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9088 - val_loss: 7.7152\n",
      "Epoch 1861/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7502 - val_loss: 9.5280\n",
      "Epoch 1862/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2703 - val_loss: 8.2139\n",
      "Epoch 1863/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1929 - val_loss: 8.9463\n",
      "Epoch 1864/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3145 - val_loss: 8.4725\n",
      "Epoch 1865/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3252 - val_loss: 8.1437\n",
      "Epoch 1866/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5774 - val_loss: 8.9356\n",
      "Epoch 1867/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6028 - val_loss: 9.0715\n",
      "Epoch 1868/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0242 - val_loss: 9.2016\n",
      "Epoch 1869/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6553 - val_loss: 8.0929\n",
      "Epoch 1870/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.2848 - val_loss: 7.6425\n",
      "Epoch 1871/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1540 - val_loss: 9.4484\n",
      "Epoch 1872/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6785 - val_loss: 8.2905\n",
      "Epoch 1873/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5748 - val_loss: 7.9338\n",
      "Epoch 1874/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6214 - val_loss: 7.9440\n",
      "Epoch 1875/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.2487 - val_loss: 9.0291\n",
      "Epoch 1876/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.2805 - val_loss: 8.0310\n",
      "Epoch 1877/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3379 - val_loss: 7.6429\n",
      "Epoch 1878/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3856 - val_loss: 8.2655\n",
      "Epoch 1879/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.1679 - val_loss: 8.3787\n",
      "Epoch 1880/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4439 - val_loss: 8.3083\n",
      "Epoch 1881/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2528 - val_loss: 8.0100\n",
      "Epoch 1882/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1465 - val_loss: 8.1928\n",
      "Epoch 1883/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3203 - val_loss: 9.2862\n",
      "Epoch 1884/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3737 - val_loss: 7.9358\n",
      "Epoch 1885/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4579 - val_loss: 8.5140\n",
      "Epoch 1886/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5861 - val_loss: 8.7078\n",
      "Epoch 1887/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3721 - val_loss: 9.4229\n",
      "Epoch 1888/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5138 - val_loss: 8.8929\n",
      "Epoch 1889/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6308 - val_loss: 8.4609\n",
      "Epoch 1890/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4806 - val_loss: 8.9382\n",
      "Epoch 1891/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4228 - val_loss: 8.6622\n",
      "Epoch 1892/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2402 - val_loss: 8.5533\n",
      "Epoch 1893/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4980 - val_loss: 9.1348\n",
      "Epoch 1894/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3624 - val_loss: 8.1603\n",
      "Epoch 1895/2000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.8821 - val_loss: 8.9703\n",
      "Epoch 1896/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4748 - val_loss: 8.4004\n",
      "Epoch 1897/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5009 - val_loss: 9.5850\n",
      "Epoch 1898/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3353 - val_loss: 8.3466\n",
      "Epoch 1899/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3675 - val_loss: 8.9013\n",
      "Epoch 1900/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1024 - val_loss: 10.0688\n",
      "Epoch 1901/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3193 - val_loss: 8.3395\n",
      "Epoch 1902/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7485 - val_loss: 8.5860\n",
      "Epoch 1903/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1916 - val_loss: 8.4151\n",
      "Epoch 1904/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4161 - val_loss: 8.7437\n",
      "Epoch 1905/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.2691 - val_loss: 8.4797\n",
      "Epoch 1906/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1772 - val_loss: 8.0875\n",
      "Epoch 1907/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1871 - val_loss: 9.3107\n",
      "Epoch 1908/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8906 - val_loss: 7.9579\n",
      "Epoch 1909/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5271 - val_loss: 8.5171\n",
      "Epoch 1910/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4181 - val_loss: 8.5106\n",
      "Epoch 1911/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3689 - val_loss: 8.2016\n",
      "Epoch 1912/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5966 - val_loss: 8.7290\n",
      "Epoch 1913/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2188 - val_loss: 8.3116\n",
      "Epoch 1914/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3557 - val_loss: 9.1383\n",
      "Epoch 1915/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5941 - val_loss: 8.5940\n",
      "Epoch 1916/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4590 - val_loss: 9.8836\n",
      "Epoch 1917/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5317 - val_loss: 9.2106\n",
      "Epoch 1918/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2278 - val_loss: 8.0406\n",
      "Epoch 1919/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4641 - val_loss: 8.5815\n",
      "Epoch 1920/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2750 - val_loss: 8.4917\n",
      "Epoch 1921/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3288 - val_loss: 8.0886\n",
      "Epoch 1922/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.2481 - val_loss: 9.4189\n",
      "Epoch 1923/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3676 - val_loss: 8.3140\n",
      "Epoch 1924/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7861 - val_loss: 9.0094\n",
      "Epoch 1925/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8460 - val_loss: 8.5457\n",
      "Epoch 1926/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5671 - val_loss: 9.3774\n",
      "Epoch 1927/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9000 - val_loss: 8.5041\n",
      "Epoch 1928/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6136 - val_loss: 8.1969\n",
      "Epoch 1929/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5314 - val_loss: 8.7829\n",
      "Epoch 1930/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7815 - val_loss: 8.4348\n",
      "Epoch 1931/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5143 - val_loss: 8.0259\n",
      "Epoch 1932/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3577 - val_loss: 8.9717\n",
      "Epoch 1933/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7610 - val_loss: 9.2302\n",
      "Epoch 1934/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3728 - val_loss: 9.2883\n",
      "Epoch 1935/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4458 - val_loss: 9.2240\n",
      "Epoch 1936/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.1181 - val_loss: 8.2550\n",
      "Epoch 1937/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2633 - val_loss: 8.2327\n",
      "Epoch 1938/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1993 - val_loss: 8.2889\n",
      "Epoch 1939/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2124 - val_loss: 9.1217\n",
      "Epoch 1940/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3792 - val_loss: 8.7713\n",
      "Epoch 1941/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4848 - val_loss: 8.7727\n",
      "Epoch 1942/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5787 - val_loss: 9.9568\n",
      "Epoch 1943/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5916 - val_loss: 8.1080\n",
      "Epoch 1944/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.1620 - val_loss: 8.8478\n",
      "Epoch 1945/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8397 - val_loss: 7.9346\n",
      "Epoch 1946/2000\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.434 - 0s 4ms/step - loss: 3.4350 - val_loss: 8.6368\n",
      "Epoch 1947/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3652 - val_loss: 9.6530\n",
      "Epoch 1948/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7779 - val_loss: 8.4835\n",
      "Epoch 1949/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.2396 - val_loss: 8.5734\n",
      "Epoch 1950/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3062 - val_loss: 8.3775\n",
      "Epoch 1951/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3580 - val_loss: 8.8217\n",
      "Epoch 1952/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3402 - val_loss: 8.2366\n",
      "Epoch 1953/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3995 - val_loss: 8.4065\n",
      "Epoch 1954/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2712 - val_loss: 10.4487\n",
      "Epoch 1955/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4506 - val_loss: 8.5816\n",
      "Epoch 1956/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3504 - val_loss: 9.3410\n",
      "Epoch 1957/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3391 - val_loss: 8.3496\n",
      "Epoch 1958/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4476 - val_loss: 8.5694\n",
      "Epoch 1959/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4114 - val_loss: 8.6640\n",
      "Epoch 1960/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7765 - val_loss: 8.3302\n",
      "Epoch 1961/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5400 - val_loss: 7.8275\n",
      "Epoch 1962/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2629 - val_loss: 10.1529\n",
      "Epoch 1963/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5655 - val_loss: 9.0531\n",
      "Epoch 1964/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6773 - val_loss: 8.9270\n",
      "Epoch 1965/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1363 - val_loss: 8.9223\n",
      "Epoch 1966/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3973 - val_loss: 8.7150\n",
      "Epoch 1967/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5626 - val_loss: 8.7284\n",
      "Epoch 1968/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9233 - val_loss: 9.0063\n",
      "Epoch 1969/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5164 - val_loss: 8.6662\n",
      "Epoch 1970/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2054 - val_loss: 9.2764\n",
      "Epoch 1971/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5699 - val_loss: 8.7315\n",
      "Epoch 1972/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.2578 - val_loss: 8.8136\n",
      "Epoch 1973/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2495 - val_loss: 8.0803\n",
      "Epoch 1974/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8122 - val_loss: 8.9298\n",
      "Epoch 1975/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4061 - val_loss: 8.6027\n",
      "Epoch 1976/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1121 - val_loss: 8.1254\n",
      "Epoch 1977/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3308 - val_loss: 9.1547\n",
      "Epoch 1978/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2333 - val_loss: 8.7053\n",
      "Epoch 1979/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.1901 - val_loss: 8.5926\n",
      "Epoch 1980/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.1334 - val_loss: 8.2189\n",
      "Epoch 1981/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.0667 - val_loss: 9.6849\n",
      "Epoch 1982/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3399 - val_loss: 9.3199\n",
      "Epoch 1983/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2862 - val_loss: 9.0297\n",
      "Epoch 1984/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2758 - val_loss: 10.2293\n",
      "Epoch 1985/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3184 - val_loss: 8.2247\n",
      "Epoch 1986/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1561 - val_loss: 8.6213\n",
      "Epoch 1987/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4985 - val_loss: 10.5768\n",
      "Epoch 1988/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6033 - val_loss: 8.2804\n",
      "Epoch 1989/2000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3146 - val_loss: 9.3163\n",
      "Epoch 1990/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4897 - val_loss: 8.4123\n",
      "Epoch 1991/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3624 - val_loss: 8.4116\n",
      "Epoch 1992/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4532 - val_loss: 9.0675\n",
      "Epoch 1993/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0851 - val_loss: 8.6578\n",
      "Epoch 1994/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2725 - val_loss: 8.8088\n",
      "Epoch 1995/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2196 - val_loss: 9.0963\n",
      "Epoch 1996/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1751 - val_loss: 8.6409\n",
      "Epoch 1997/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2286 - val_loss: 8.5118\n",
      "Epoch 1998/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3338 - val_loss: 8.6072\n",
      "Epoch 1999/2000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6608 - val_loss: 8.1902\n",
      "Epoch 2000/2000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4390 - val_loss: 10.4668\n"
     ]
    }
   ],
   "source": [
    "history = mpgmodel.fit(train_x, train_y, batch_size=8, epochs=2000,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 7.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.975869655609131"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpgmodel.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=mpgmodel.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('Coefficient of determination: %.2f'% r2_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4.972, Test: 8.540\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plot feature import\n",
    "train_mse = mpgmodel.evaluate(train_x, train_y, verbose=0)\n",
    "test_mse = mpgmodel.evaluate(test_x, test_y, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "\n",
    "\n",
    "# plot loss during training\n",
    "plt.title('Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpgmodel.save('mpg_car.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
